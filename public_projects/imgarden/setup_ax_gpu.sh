#!/bin/bash

echo "ðŸ”§ A.X-3.1-Light ëª¨ë¸ ì„¤ì • ì‹œìž‘..."

# ê¸°ì¡´ ì»¨í…Œì´ë„ˆ ì •ë¦¬
docker stop ax-chatbot 2>/dev/null
docker rm ax-chatbot 2>/dev/null

# í”„ë¡œì íŠ¸ ì••ì¶• í•´ì œ
cd /home/isangjae
rm -rf naviyam_backend
tar -xzf naviyam_ax_deploy.tar.gz
mv naviyam_backend_runnable_20250806_112316 naviyam_backend

# Dockerfile ìƒì„±
cat > /home/isangjae/naviyam_backend/Dockerfile << 'EOF'
FROM nvidia/cuda:12.2.0-runtime-ubuntu22.04

RUN apt-get update && apt-get install -y \
    python3.10 \
    python3.10-dev \
    python3-pip \
    git \
    wget \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app
COPY . /app/

RUN pip3 install --no-cache-dir \
    torch \
    transformers \
    accelerate \
    bitsandbytes \
    fastapi \
    uvicorn \
    faiss-cpu \
    numpy \
    scikit-learn \
    pandas \
    sentencepiece \
    protobuf \
    peft \
    GPUtil

ENV PYTHONPATH=/app
ENV USE_4BIT=true
ENV MODEL_NAME=skt/A.X-3.1-Light
ENV CUDA_VISIBLE_DEVICES=0

EXPOSE 8000

CMD ["python3", "-m", "uvicorn", "api.server:app", "--host", "0.0.0.0", "--port", "8000"]
EOF

# Docker ì´ë¯¸ì§€ ë¹Œë“œ
echo "ðŸ”¨ Docker ì´ë¯¸ì§€ ë¹Œë“œ ì¤‘..."
cd /home/isangjae/naviyam_backend
docker build -t ax-chatbot:latest .

# ì»¨í…Œì´ë„ˆ ì‹¤í–‰
echo "ðŸš€ ì»¨í…Œì´ë„ˆ ì‹œìž‘..."
docker run -d \
    --name ax-chatbot \
    --gpus all \
    -p 8000:8000 \
    -e USE_4BIT=true \
    -e MODEL_NAME="skt/A.X-3.1-Light" \
    -e CUDA_VISIBLE_DEVICES=0 \
    -v /home/isangjae/model_cache:/root/.cache/huggingface \
    ax-chatbot:latest

echo "â³ ì„œë²„ ì‹œìž‘ ëŒ€ê¸° ì¤‘..."
sleep 30

echo "ðŸ“‹ ì»¨í…Œì´ë„ˆ ìƒíƒœ:"
docker ps -a | grep ax-chatbot

echo "ðŸ“‹ ì»¨í…Œì´ë„ˆ ë¡œê·¸:"
docker logs --tail 50 ax-chatbot

echo "âœ… ë°°í¬ ì™„ë£Œ!"
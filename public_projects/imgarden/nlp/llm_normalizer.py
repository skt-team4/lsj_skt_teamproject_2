"""
LLM ê¸°ë°˜ ì…ë ¥ ì •ê·œí™” ëª¨ë“ˆ
ë³µì¡í•œ ìì—°ì–´ë¥¼ ì •ë¦¬ëœ í˜•íƒœë¡œ ë³€í™˜ + ì•„ë™ ì¹œí™”ì  ì‘ë‹µ ìƒì„±
"""

import json
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
import logging

logger = logging.getLogger(__name__)

@dataclass
class LLMNormalizedOutput:
    """LLMì´ êµ¬ì¡°í™”í•œ ì¶œë ¥"""
    normalized_text: str  # ì •ë¦¬ëœ ë¬¸ì¥
    identified_entities: Dict[str, Any]  # ì¶”ì¶œëœ ì—”í‹°í‹°ë“¤
    context_resolution: Dict[str, Any]  # ë§¥ë½ í•´ê²° ì •ë³´
    confidence: float  # LLM ì‹ ë¢°ë„
    raw_llm_output: str  # ì›ë³¸ LLM ì‘ë‹µ

class LLMNormalizer:
    """LLM ê¸°ë°˜ ì…ë ¥ ì •ê·œí™”ê¸°"""

    def __init__(self, model=None):
        self.model = model

    def normalize_user_input(
        self,
        user_input: str,
        conversation_history: List[Dict] = None,
        user_context: Dict = None
    ) -> LLMNormalizedOutput:
        """ì‚¬ìš©ì ì…ë ¥ì„ LLMìœ¼ë¡œ êµ¬ì¡°í™” (ë°ì´í„° ì¶”ì¶œ ì „ìš©)"""

        if not self.model:
            # LLM ì—†ìœ¼ë©´ ì›ë³¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
            return LLMNormalizedOutput(
                normalized_text=user_input,
                identified_entities={},
                context_resolution={},
                confidence=0.5,
                raw_llm_output=""
            )

        try:
            # ë°ì´í„° ì¶”ì¶œ ì „ìš© í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = self._build_data_extraction_prompt(
                user_input, conversation_history, user_context
            )

            # LLM ì‹¤í–‰
            llm_result = self.model.generate_text(
                prompt=prompt,
                max_new_tokens=300,
                temperature=0.1  # ë‚®ì€ ì˜¨ë„ë¡œ ì¼ê´€ì„± í™•ë³´
            )

            # JSON íŒŒì‹±
            parsed_output = self._parse_llm_output(llm_result["text"])

            return LLMNormalizedOutput(
                normalized_text=parsed_output.get("normalized_text", user_input),
                identified_entities=parsed_output.get("identified_entities", {}),
                context_resolution=parsed_output.get("context_resolution", {}),
                confidence=parsed_output.get("confidence", 0.8),
                raw_llm_output=llm_result["text"]
            )

        except Exception as e:
            logger.error(f"LLM ì •ê·œí™” ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ì‹œ ì›ë³¸ ë°˜í™˜
            return LLMNormalizedOutput(
                normalized_text=user_input,
                identified_entities={},
                context_resolution={},
                confidence=0.3,
                raw_llm_output=str(e)
            )

    def generate_child_friendly_response(
        self,
        extracted_info,
        recommendations: List[Dict],
        conversation_context: List[Dict] = None,
        user_profile = None
    ) -> str:
        """ì•„ë™ ì¹œí™”ì  ì‘ë‹µ ìƒì„± (LLM ì‚¬ìš©)"""

        if not self.model:
            return ""

        try:
            # ì•„ë™ ì‘ë‹µ ì „ìš© í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = self._build_child_friendly_prompt(
                extracted_info, recommendations, conversation_context, user_profile
            )

            # LLM ì‹¤í–‰
            llm_result = self.model.generate_text(
                prompt=prompt,
                max_new_tokens=150,
                temperature=0.7  # ë” ì°½ì˜ì ìœ¼ë¡œ
            )

            # ì‘ë‹µ ì •ì œ
            return self._clean_child_response(llm_result["text"])

        except Exception as e:
            logger.error(f"ì•„ë™ ì¹œí™”ì  ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            return ""

    def _build_data_extraction_prompt(
        self,
        user_input: str,
        conversation_history: List[Dict],
        user_context: Dict
    ) -> str:
        """ë°ì´í„° ì¶”ì¶œ ì „ìš© í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""

        prompt_parts = [
            "ìŒì‹ ì£¼ë¬¸ ì •ë³´ë¥¼ êµ¬ì¡°í™”í•˜ëŠ” AIì…ë‹ˆë‹¤. ì‚¬ìš©ì ì…ë ¥ì—ì„œ í•µì‹¬ ì •ë³´ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.",
            ""
        ]

        # Few-shot ì˜ˆì‹œë“¤
        prompt_parts.extend([
            "ì˜ˆì‹œ:",
            'ì…ë ¥: "ì¹˜í‚¨ ë¨¹ê³  ì‹¶ì–´"',
            'ì¶œë ¥: {"normalized_text": "ì¹˜í‚¨ì„ ì£¼ë¬¸í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤", "food_type": "ì¹˜í‚¨", "budget": null, "companions": [], "confidence": 0.9}',
            '',
            'ì…ë ¥: "ì¹œêµ¬ 2ëª…ì´ë‘ 1ë§Œì›ìœ¼ë¡œ ë­ ë¨¹ì„ê¹Œ?"', 
            'ì¶œë ¥: {"normalized_text": "ì¹œêµ¬ 2ëª…ê³¼ í•¨ê»˜ 1ë§Œì› ì˜ˆì‚°ìœ¼ë¡œ ìŒì‹ì„ ì°¾ê³  ìˆìŠµë‹ˆë‹¤", "food_type": null, "budget": 10000, "companions": ["ì¹œêµ¬"], "confidence": 0.8}',
            '',
            'ì…ë ¥: "ë§¤ìš´ê±° ë§ê³  ìˆœí•œê±¸ë¡œ"',
            'ì¶œë ¥: {"normalized_text": "ë§¤ìš´ ìŒì‹ ëŒ€ì‹  ìˆœí•œ ìŒì‹ì„ ì›í•©ë‹ˆë‹¤", "food_type": null, "budget": null, "companions": [], "taste_preference": "ìˆœí•œ", "confidence": 0.9}',
            ""
        ])

        # ëŒ€í™” ë§¥ë½ (ìµœê·¼ 1ê°œë§Œ)
        if conversation_history and conversation_history[-1:]:
            last_conv = conversation_history[-1]
            prompt_parts.append(f"ì´ì „ëŒ€í™”: ì‚¬ìš©ìã€Œ{last_conv.get('user_input', '')}ã€â†’ AIã€Œ{last_conv.get('bot_response', '')[:30]}...ã€")
            prompt_parts.append("")

        # ì‚¬ìš©ì ë§¥ë½ (ê°„ê²°í•˜ê²Œ)
        if user_context:
            context_info = []
            if user_context.get("preferred_foods"):
                context_info.append(f"ì„ í˜¸ìŒì‹:{user_context['preferred_foods'][0]}")
            if user_context.get("usual_budget"):
                context_info.append(f"í‰ì†Œì˜ˆì‚°:{user_context['usual_budget']}ì›")
            if context_info:
                prompt_parts.append(f"ì‚¬ìš©ìì •ë³´: {', '.join(context_info)}")
                prompt_parts.append("")

        # í˜„ì¬ ì…ë ¥ ë° ì¶œë ¥ ìš”ì²­
        prompt_parts.extend([
            f'ì…ë ¥: "{user_input}"',
            'ì¶œë ¥ (JSONë§Œ):',
            '{"normalized_text": "ëª…í™•í•œ ë¬¸ì¥", "food_type": "ìŒì‹ì¢…ë¥˜ë˜ëŠ”null", "budget": ìˆ«ìë˜ëŠ”null, "companions": ["ë™ë°˜ìë“¤"], "taste_preference": "ë§›ì„ í˜¸ë˜ëŠ”null", "urgency": "ê¸‰í•¨/ë³´í†µ/ì—¬ìœ ë˜ëŠ”null", "special_requests": ["íŠ¹ë³„ìš”ì²­ë“¤"], "confidence": 0.0~1.0}'
        ])

        return "\n".join(prompt_parts)

    def _build_child_friendly_prompt(
        self,
        extracted_info,
        recommendations: List[Dict],
        conversation_context: List[Dict] = None,
        user_profile = None
    ) -> str:
        """ì•„ë™ ì¹œí™”ì  ì‘ë‹µ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""

        prompt_parts = [
            "ë‹¹ì‹ ì€ 'ë‚˜ë¹„ì–Œ' - ì•„ì´ë“¤ì„ ìœ„í•œ ì¹œê·¼í•œ ìŒì‹ ì¶”ì²œ AIì…ë‹ˆë‹¤.",
            "íŠ¹ì§•: ë°ê³  ë”°ëœ»í•œ ì–¸ë‹ˆ/ëˆ„ë‚˜ í†¤, ê°„ë‹¨ëª…ë£Œ, ì´ëª¨í‹°ì½˜ ì‚¬ìš© ğŸ˜Šâœ¨",
            ""
        ]

        # Few-shot ì˜ˆì‹œë“¤
        prompt_parts.extend([
            "ì˜ˆì‹œ:",
            'ì‚¬ìš©ì: "ì¹˜í‚¨ ë¨¹ê³  ì‹¶ì–´"',
            'ë‚˜ë¹„ì–Œ: "ì¹˜í‚¨ ì¢‹ì•„ìš”! ë§›ìˆëŠ” ì°©í•œê°€ê²Œ ì¹˜í‚¨ ì¶”ì²œí•´ë“œë¦´ê²Œìš” ğŸ—âœ¨"',
            '',
            'ì‚¬ìš©ì: "ì˜ˆì‚°ì´ ë¶€ì¡±í•´ìš”"', 
            'ë‚˜ë¹„ì–Œ: "ê´œì°®ì•„ìš”! ì €ë ´í•˜ë©´ì„œë„ ë§›ìˆëŠ” ê³³ ì°¾ì•„ë“œë¦´ê²Œìš” ğŸ˜Š"',
            '',
            'ì‚¬ìš©ì: "ê³ ë§ˆì›Œìš”"',
            'ë‚˜ë¹„ì–Œ: "ì²œë§Œì—ìš”! ë§›ìˆê²Œ ë“œì„¸ìš” ğŸ½ï¸"',
            ""
        ])

        # ê°œì¸í™” ì •ë³´ (ê°„ì†Œí™”)
        if user_profile and hasattr(user_profile, 'preferred_categories') and user_profile.preferred_categories:
            prompt_parts.append(f"ì‚¬ìš©ìì„ í˜¸: {user_profile.preferred_categories[0]}")
            prompt_parts.append("")

        # ëŒ€í™” ë§¥ë½ (ìµœê·¼ 1ê°œë§Œ)
        if conversation_context and conversation_context[-1:]:
            last_ctx = conversation_context[-1]
            prompt_parts.append(f"ì´ì „: ì‚¬ìš©ìã€Œ{last_ctx.get('user_input', '')}ã€â†’ ë‚˜ë¹„ì–Œã€Œ{last_ctx.get('bot_response', '')[:20]}...ã€")
            prompt_parts.append("")

        # í˜„ì¬ ì…ë ¥
        prompt_parts.append(f'ì‚¬ìš©ì: "{extracted_info.raw_text}"')

        # ì¶”ì²œ ì •ë³´ (ê°„ê²°í•˜ê²Œ)
        if recommendations:
            rec_info = []
            for rec in recommendations[:2]:  # ìµœëŒ€ 2ê°œë§Œ
                shop_name = rec.get('shop_name', '')
                menu_name = rec.get('menu_name', '')
                price = rec.get('price', 0)
                is_good = rec.get('is_good_influence_shop', False)
                rec_info.append(f"{shop_name} {menu_name} {price}ì›{'[ì°©í•œê°€ê²Œ]' if is_good else ''}")
            prompt_parts.append(f"ì¶”ì²œê°€ëŠ¥: {', '.join(rec_info)}")
            prompt_parts.append("")

        prompt_parts.extend([
            "ë‚˜ë¹„ì–Œì˜ ë”°ëœ»í•œ ì‘ë‹µ (êµ¬ì²´ì  ì¶”ì²œ í¬í•¨, 1-2ë¬¸ì¥, ì´ëª¨í‹°ì½˜ í¬í•¨):",
            ""
        ])

        return "\n".join(prompt_parts)

    def _build_user_context(self, user_profile) -> str:
        """UserProfile â†’ í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸ ë³€í™˜"""
        if not user_profile:
            return ""
            
        context_parts = []
        
        # ì„ í˜¸ ìŒì‹ ì¹´í…Œê³ ë¦¬
        if user_profile.preferred_categories:
            context_parts.append(f"- ì¢‹ì•„í•˜ëŠ” ìŒì‹: {', '.join(user_profile.preferred_categories)}")
        
        # í‰ê·  ì˜ˆì‚°
        if user_profile.average_budget:
            context_parts.append(f"- í‰ì†Œ ì˜ˆì‚°: {user_profile.average_budget}ì› ë‚´ì™¸")
        
        # ë§› ì„ í˜¸ë„
        if hasattr(user_profile, 'taste_preferences') and user_profile.taste_preferences:
            taste_info = []
            for taste, score in user_profile.taste_preferences.items():
                if score > 0.7:
                    level = "ë§¤ìš° ì¢‹ì•„í•¨"
                elif score > 0.3:
                    level = "ì¢‹ì•„í•¨"
                else:
                    level = "ë³´í†µ"
                taste_info.append(f"{taste} {level}")
            if taste_info:
                context_parts.append(f"- ë§› ì„ í˜¸: {', '.join(taste_info)}")
        
        # ë™ë°˜ì íŒ¨í„´
        if hasattr(user_profile, 'companion_patterns') and user_profile.companion_patterns:
            context_parts.append(f"- ì£¼ë¡œ í•¨ê»˜: {', '.join(user_profile.companion_patterns)}")
        
        # ëŒ€í™” ìŠ¤íƒ€ì¼
        if hasattr(user_profile, 'conversation_style') and user_profile.conversation_style:
            style_map = {
                "friendly": "ì¹œê·¼í•œ ëŒ€í™” ì„ í˜¸",
                "formal": "ì •ì¤‘í•œ ëŒ€í™” ì„ í˜¸", 
                "casual": "í¸ì•ˆí•œ ëŒ€í™” ì„ í˜¸"
            }
            style_desc = style_map.get(user_profile.conversation_style, user_profile.conversation_style)
            context_parts.append(f"- ëŒ€í™” ìŠ¤íƒ€ì¼: {style_desc}")
        
        # ìµœê·¼ ì£¼ë¬¸ ì´ë ¥ (ê°„ë‹¨í•˜ê²Œ)
        if hasattr(user_profile, 'recent_orders') and user_profile.recent_orders:
            recent_foods = []
            for order in user_profile.recent_orders[-3:]:  # ìµœê·¼ 3ê°œë§Œ
                if isinstance(order, dict) and 'food_type' in order:
                    recent_foods.append(order['food_type'])
            if recent_foods:
                context_parts.append(f"- ìµœê·¼ ì£¼ë¬¸: {', '.join(recent_foods)}")
        
        return "\n".join(context_parts)

    def _parse_llm_output(self, llm_text: str) -> Dict[str, Any]:
        """LLM ì¶œë ¥ JSON íŒŒì‹± (ê°„ì†Œí™”)"""
        try:
            # JSON ë¶€ë¶„ ì¶”ì¶œ
            start_idx = llm_text.find('{')
            end_idx = llm_text.rfind('}') + 1

            if start_idx == -1 or end_idx == 0:
                raise ValueError("JSON í˜•íƒœë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")

            json_str = llm_text[start_idx:end_idx]
            # ê°„ë‹¨í•œ ì •ì œë§Œ
            json_str = json_str.replace('\n', ' ').replace('\t', ' ')
            
            parsed = json.loads(json_str)

            # ê°„ì†Œí™”ëœ êµ¬ì¡°ë¡œ ë°˜í™˜
            return {
                "normalized_text": parsed.get("normalized_text", llm_text[:100]),
                "identified_entities": {
                    "food_type": parsed.get("food_type"),
                    "budget": parsed.get("budget"), 
                    "companions": parsed.get("companions", []),
                    "taste_preference": parsed.get("taste_preference"),
                    "urgency": parsed.get("urgency"),
                    "special_requests": parsed.get("special_requests", [])
                },
                "context_resolution": {},  # í•„ìš”ì‹œ ë‚˜ì¤‘ì— í™•ì¥
                "confidence": parsed.get("confidence", 0.8)
            }

        except Exception as e:
            logger.warning(f"LLM ì¶œë ¥ íŒŒì‹± ì‹¤íŒ¨: {e}")
            # íŒŒì‹± ì‹¤íŒ¨ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                "normalized_text": llm_text.strip()[:100] if llm_text.strip() else "ìŒì‹ ì¶”ì²œ ìš”ì²­",
                "identified_entities": {},
                "context_resolution": {},
                "confidence": 0.3
            }

    def _clean_child_response(self, response: str) -> str:
        """ì•„ë™ ì¹œí™”ì  ì‘ë‹µ ì •ì œ"""
        if not response:
            return ""

        # ë¶ˆí•„ìš”í•œ ë¶€ë¶„ ì œê±°
        response = response.strip()

        # ì •ì§€ ë‹¨ì–´ ì´í›„ ì œê±°
        stop_indicators = ["ì‚¬ìš©ì:", "User:", "ë‚˜ë¹„ì–Œ:", "AI:", "\n\n", "###"]
        for stop in stop_indicators:
            if stop in response:
                response = response.split(stop)[0].strip()

        # íŠ¹ìˆ˜ ë¬¸ìë‚˜ ì´ìƒí•œ íŒ¨í„´ ì œê±°
        import re
        response = re.sub(r'[#\[\]]\.?', '', response)  # #, [], ì œê±°
        response = re.sub(r'\{.*?\}', '', response)  # ì¤‘ê´„í˜¸ ë‚´ìš© ì œê±°
        response = re.sub(r'\s+', ' ', response)  # ì¤‘ë³µ ê³µë°± ì œê±°

        # ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸´ ì‘ë‹µ ì²˜ë¦¬  
        if len(response) < 8:  # ë” ì—„ê²©í•˜ê²Œ
            return ""
        elif len(response) > 200:  # ê¸¸ì´ ì œí•œ ëŠ˜ë¦¼
            sentences = response.split('.')
            if len(sentences) > 1:
                response = sentences[0] + '.'
            else:
                response = response[:200] + '...'

        # ë§ˆì§€ë§‰ ì •ì œ
        response = response.strip()
        if response and not response.endswith(('.', '!', '?', 'ğŸ˜Š', 'âœ¨', 'ğŸ½ï¸')):
            response += '!'

        return response

    def should_use_llm_normalization(self, text: str) -> bool:
        """LLM ì •ê·œí™” ì‚¬ìš© ì—¬ë¶€ ê²°ì •"""

        # ë„ˆë¬´ ì§§ì€ ì…ë ¥ì€ LLM ë¶ˆí•„ìš”
        if len(text.strip()) < 5:
            return False

        # ë³µì¡í•œ ì…ë ¥ì— ëŒ€í•´ì„œë§Œ LLM ì‚¬ìš©
        complexity_indicators = [
            len(text) > 25,  # ê¸´ ë¬¸ì¥
            "ì•„ê¹Œ" in text or "ê·¸ê±°" in text or "ì €ê¸°" in text or "ì´ê±°" in text,  # ì°¸ì¡° í‘œí˜„
            text.count(" ") > 6,  # ë§ì€ ë‹¨ì–´
            any(word in text for word in ["ì´ë‘", "í•˜ê³ ", "ê·¸ë¦¬ê³ ", "ê·¼ë°", "ê·¸ëŸ°ë°"]),  # ë³µí•© í‘œí˜„
            "ëª…ì´ë‘" in text or "ë¶„ì´ë‘" in text or "ì‚¬ëŒ" in text,  # ì¸ì› í‘œí˜„
            any(word in text for word in ["ë§¤ìš´", "ì•ˆë§¤ìš´", "ìˆœí•œ", "ë‹´ë°±í•œ", "ì§œê²Œ", "ì‹±ê²ê²Œ"]),  # ë§› ì„ í˜¸ë„
            any(word in text for word in ["ê¸‰í•´", "ë¹¨ë¦¬", "ì²œì²œíˆ", "ë‚˜ì¤‘ì—"]),  # ì‹œê¸‰ì„±
        ]

        # 2ê°œ ì´ìƒì˜ ë³µì¡ì„± ì§€í‘œê°€ ìˆìœ¼ë©´ LLM ì‚¬ìš©
        return sum(complexity_indicators) >= 2

    def should_use_llm_response(self, extracted_info, conversation_context) -> bool:
        """LLM ì‘ë‹µ ìƒì„± ì‚¬ìš© ì—¬ë¶€ ê²°ì •"""

        # ê°„ë‹¨í•œ ì¼€ì´ìŠ¤ëŠ” í…œí”Œë¦¿ìœ¼ë¡œ ì¶©ë¶„
        if not extracted_info or not extracted_info.raw_text:
            return False

        creative_indicators = [
            extracted_info.confidence < 0.8,  # ë” ìì£¼ LLM ì‚¬ìš© (0.7â†’0.8)
            len(conversation_context) > 2,    # ë” ì¼ì° LLM ì‚¬ìš© (3â†’2)
            extracted_info.intent.value == "general_chat",  # ì¡ë‹´
            any(word in extracted_info.raw_text.lower() for word in
                ["ê³ ë§ˆì›Œ", "ê°ì‚¬", "ì˜ë¨¹ì—ˆ", "ë§›ìˆì—ˆ", "ì¢‹ì•˜", "ë³„ë¡œ", "ì•„ì‰¬ì› ", "ì¶”ì²œ"]),  # ê°ì • í‘œí˜„ + ì¶”ì²œ ìš”ì²­
            len(extracted_info.raw_text.split()) > 8,  # ë” ì§§ì€ ì…ë ¥ë¶€í„° LLM ì‚¬ìš© (10â†’8)
            "ëª¨ë¥´ê² " in extracted_info.raw_text,  # ì• ë§¤í•œ í‘œí˜„
        ]

        # íŠ¹ë³„ ìš”ì²­ì´ ìˆìœ¼ë©´ LLM ì‚¬ìš©
        if (hasattr(extracted_info, 'entities') and
            extracted_info.entities and
            extracted_info.entities.special_requirements and
            len(extracted_info.entities.special_requirements) > 0):
            creative_indicators.append(True)

        # 1ê°œ ì´ìƒì˜ ì°½ì˜ì  ì§€í‘œê°€ ìˆìœ¼ë©´ LLM ì‚¬ìš©
        return any(creative_indicators)

    def analyze_for_learning(self, text: str) -> Dict[str, Any]:
        """í•™ìŠµìš© í…ìŠ¤íŠ¸ ë¶„ì„ (ì¶”ê°€ ê¸°ëŠ¥)"""
        try:
            analysis = {
                "text_length": len(text),
                "word_count": len(text.split()),
                "has_references": any(word in text for word in ["ì•„ê¹Œ", "ê·¸ê±°", "ì €ê¸°", "ì´ê±°"]),
                "has_complex_expressions": any(word in text for word in ["ì´ë‘", "í•˜ê³ ", "ê·¸ë¦¬ê³ "]),
                "has_taste_preferences": any(word in text for word in ["ë§¤ìš´", "ìˆœí•œ", "ì§œê²Œ", "ì‹±ê²ê²Œ"]),
                "has_urgency": any(word in text for word in ["ê¸‰í•´", "ë¹¨ë¦¬", "ì²œì²œíˆ"]),
                "has_emotions": any(word in text for word in ["ê³ ë§ˆì›Œ", "ê°ì‚¬", "ì¢‹ì•„", "ì‹«ì–´"]),
                "complexity_score": self._calculate_complexity_score(text)
            }

            return analysis
        except Exception as e:
            logger.error(f"í•™ìŠµìš© ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}

    def _calculate_complexity_score(self, text: str) -> float:
        """í…ìŠ¤íŠ¸ ë³µì¡ë„ ì ìˆ˜ ê³„ì‚°"""
        score = 0.0

        # ê¸¸ì´ ê¸°ë°˜ ì ìˆ˜
        score += min(len(text) / 50.0, 1.0) * 0.3

        # ë‹¨ì–´ ìˆ˜ ê¸°ë°˜ ì ìˆ˜
        score += min(len(text.split()) / 15.0, 1.0) * 0.3

        # ë³µì¡ì„± ì§€í‘œ ê¸°ë°˜ ì ìˆ˜
        complexity_features = [
            "ì•„ê¹Œ" in text, "ê·¸ê±°" in text, "ì´ë‘" in text, "í•˜ê³ " in text,
            "ë§¤ìš´" in text, "ìˆœí•œ" in text, "ê¸‰í•´" in text, "ëª…ì´ë‘" in text
        ]
        score += sum(complexity_features) / len(complexity_features) * 0.4

        return min(score, 1.0)
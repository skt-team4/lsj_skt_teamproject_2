"""
í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ëª¨ë“ˆ
ì•„ë™ ì¹œí™”ì  í‘œí˜„ ë³´ì¡´í•˜ë©´ì„œ ì •ì œ
"""

import re
import string
from typing import List, Dict, Optional, Tuple
import logging
from dataclasses import dataclass
from enum import Enum

logger = logging.getLogger(__name__)


class EmotionType(Enum):
    """ê°ì • íƒ€ì…"""
    POSITIVE = "positive"
    NEGATIVE = "negative"
    NEUTRAL = "neutral"
    EXCITED = "excited"  # ì‹ ë‚¨, ê¸°ëŒ€
    DISAPPOINTED = "disappointed"  # ì‹¤ë§


@dataclass
class PreprocessResult:
    """ì „ì²˜ë¦¬ ê²°ê³¼"""
    original_text: str  # ì›ë³¸ í…ìŠ¤íŠ¸
    cleaned_text: str  # ì •ì œëœ í…ìŠ¤íŠ¸
    normalized_text: str  # ì •ê·œí™”ëœ í…ìŠ¤íŠ¸
    extracted_keywords: List[str]  # ì¶”ì¶œëœ í‚¤ì›Œë“œ
    emotion: EmotionType  # ê°ì • ë¶„ì„ ê²°ê³¼
    confidence: float  # ì‹ ë¢°ë„
    preserved_expressions: List[str]  # ë³´ì¡´ëœ í‘œí˜„ë“¤


class NaviyamTextPreprocessor:
    """ë‚˜ë¹„ì–Œ íŠ¹í™” í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ê¸°"""

    def __init__(self, preserve_expressions: bool = True):
        """
        Args:
            preserve_expressions: ì•„ë™ ì¹œí™”ì  í‘œí˜„ ë³´ì¡´ ì—¬ë¶€
        """
        self.preserve_expressions = preserve_expressions

        # ë³´ì¡´í•  ì•„ë™ ì¹œí™”ì  í‘œí˜„ë“¤
        self.preserve_patterns = {
            'laughter': [r'ã…‹+', r'ã…+', r'í—¤+', r'í•˜+'],
            'excitement': [r'\^+', r'!+', r'~+'],
            'sadness': [r'ã… +', r'ã…œ+', r'í‘+'],
            'heart': [r'â™¥+', r'â¤+', r'ğŸ’•', r'â£ï¸'],
            'emphasis': [r'\?+', r'\.{2,}']
        }

        # ìŒì‹ ê´€ë ¨ í‚¤ì›Œë“œ ì‚¬ì „
        self.food_keywords = {
            'categories': [
                'í•œì‹', 'ì¤‘ì‹', 'ì¼ì‹', 'ì–‘ì‹', 'ì¹˜í‚¨', 'í”¼ì', 'í–„ë²„ê±°',
                'ë¶„ì‹', 'ì¹´í˜', 'ë””ì €íŠ¸', 'ì•„ì‹œì•ˆ', 'ë©•ì‹œì¹¸', 'ì¸ë„'
            ],
            'foods': [
                'ê¹€ì¹˜ì°Œê°œ', 'ëœì¥ì°Œê°œ', 'ë¹„ë¹”ë°¥', 'ëƒ‰ë©´', 'ë¼ë©´', 'ë–¡ë³¶ì´',
                'ì¹˜í‚¨', 'í”¼ì', 'í–„ë²„ê±°', 'íŒŒìŠ¤íƒ€', 'ìŠ¤í…Œì´í¬', 'ì´ˆë°¥',
                'ì§œì¥ë©´', 'ì§¬ë½•', 'íƒ•ìˆ˜ìœ¡', 'ë§ˆë¼íƒ•', 'ìŒ€êµ­ìˆ˜', 'íŒŒë“œíƒ€ì´',
                'ì¹´ë ˆ', 'ëˆê¹ŒìŠ¤', 'ìš°ë™', 'ì†Œë°”', 'ê·œë™', 'ì˜¤ë¯€ë¼ì´ìŠ¤'
            ],
            'tastes': [
                'ë§µë‹¤', 'ë‹¬ë‹¤', 'ì§œë‹¤', 'ì‹œë‹¤', 'ì“°ë‹¤', 'ê³ ì†Œí•˜ë‹¤', 'ë‹´ë°±í•˜ë‹¤',
                'ì§„í•˜ë‹¤', 'ê¹”ë”í•˜ë‹¤', 'ë¶€ë“œëŸ½ë‹¤', 'ì«„ê¹ƒí•˜ë‹¤', 'ë°”ì‚­í•˜ë‹¤'
            ],
            'cooking_methods': [
                'ë³¶ìŒ', 'ì°œ', 'êµ¬ì´', 'íŠ€ê¹€', 'ì¡°ë¦¼', 'íƒ•', 'êµ­', 'ì°Œê°œ',
                'ë¬´ì¹¨', 'ì ˆì„', 'ìƒ', 'íšŒ'
            ]
        }

        # ê°ì • ë¶„ì„ìš© í‚¤ì›Œë“œ
        self.emotion_keywords = {
            EmotionType.POSITIVE: [
                'ë§›ìˆë‹¤', 'ì¢‹ë‹¤', 'ìµœê³ ', 'ì§±', 'êµ¿', 'ì™„ë²½', 'ë§Œì¡±', 'í–‰ë³µ',
                'ê°ì‚¬', 'ì¶”ì²œ', 'ë‹¤ì‹œ', 'ë˜', 'ìì£¼', 'ì¢‹ì•„í•´', 'ì‚¬ë‘í•´'
            ],
            EmotionType.NEGATIVE: [
                'ë§›ì—†ë‹¤', 'ë³„ë¡œ', 'ì‹¤ë§', 'í›„íšŒ', 'ìµœì•…', 'ë‚˜ì˜ë‹¤', 'ì‹«ë‹¤',
                'ë‹¤ì‹œëŠ”', 'ì•ˆê°€', 'ë¹„ì¶”', 'ëˆì•„ê¹Œì›Œ', 'ì§œì¦'
            ],
            EmotionType.EXCITED: [
                'ì™€', 'ìš°ì™€', 'ëŒ€ë°•', 'ì©ë‹¤', 'ë¯¸ì³¤ë‹¤', 'ê°œë§›ìˆì–´', 'ì¡´ë§›',
                'í‚¹ì™•ì§±', 'ë ˆì „ë“œ', 'ê°“', 'í˜œì', 'ê¿€ë§›'
            ],
            EmotionType.DISAPPOINTED: [
                'ì•„ì‰½ë‹¤', 'ê·¸ëƒ¥ê·¸ëƒ¥', 'ë³´í†µ', 'í‰ë²”', 'ê¸°ëŒ€ì´í•˜', 'ë­”ê°€',
                'ì¢€ë”', 'ì•„ê¹ë‹¤', 'ì• ë§¤í•˜ë‹¤'
            ]
        }

        # ì˜ˆì‚°/ê°€ê²© ê´€ë ¨ í‘œí˜„
        self.budget_patterns = [
            r'(\d+)\s*ì›',
            r'(\d+)\s*ì²œì›',
            r'(\d+)\s*ë§Œì›',
            r'(\d{1,2})\s*ì²œ',
            r'(\d{1,3})\s*ë§Œ',
            r'ë¹„ì‹¸ë‹¤?', r'ì‹¸ë‹¤?', r'ì €ë ´í•˜ë‹¤?', r'ê°€ì„±ë¹„', r'í˜œì'
        ]

        # ë™ë°˜ì íŒ¨í„´
        self.companion_patterns = [
            r'ì¹œêµ¬', r'ê°€ì¡±', r'ì—„ë§ˆ', r'ì•„ë¹ ', r'í˜•', r'ëˆ„ë‚˜', r'ì–¸ë‹ˆ', r'ì˜¤ë¹ ',
            r'ë™ìƒ', r'í˜¼ì', r'ì• ì¸', r'ë‚¨ì¹œ', r'ì—¬ì¹œ', r'ê°™ì´', r'í•¨ê»˜'
        ]

    def preprocess(self, text: str) -> PreprocessResult:
        """ì „ì²´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
        if not text or not text.strip():
            return PreprocessResult(
                original_text=text,
                cleaned_text="",
                normalized_text="",
                extracted_keywords=[],
                emotion=EmotionType.NEUTRAL,
                confidence=0.0,
                preserved_expressions=[]
            )

        original_text = text

        # 1. ë³´ì¡´í•  í‘œí˜„ ì¶”ì¶œ
        preserved_expressions = self._extract_preserved_expressions(text)

        # 2. ê¸°ë³¸ ì •ì œ
        cleaned_text = self._basic_cleaning(text)

        # 3. ì •ê·œí™”
        normalized_text = self._normalize_text(cleaned_text)

        # 4. í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = self._extract_keywords(normalized_text)

        # 5. ê°ì • ë¶„ì„
        emotion, confidence = self._analyze_emotion(normalized_text, preserved_expressions)

        return PreprocessResult(
            original_text=original_text,
            cleaned_text=cleaned_text,
            normalized_text=normalized_text,
            extracted_keywords=keywords,
            emotion=emotion,
            confidence=confidence,
            preserved_expressions=preserved_expressions
        )

    def _extract_preserved_expressions(self, text: str) -> List[str]:
        """ë³´ì¡´í•  í‘œí˜„ë“¤ ì¶”ì¶œ"""
        if not self.preserve_expressions:
            return []

        preserved = []

        for expr_type, patterns in self.preserve_patterns.items():
            for pattern in patterns:
                matches = re.findall(pattern, text, re.IGNORECASE)
                for match in matches:
                    preserved.append(f"{expr_type}:{match}")

        return preserved

    def _basic_cleaning(self, text: str) -> str:
        """ê¸°ë³¸ í…ìŠ¤íŠ¸ ì •ì œ"""
        # HTML íƒœê·¸ ì œê±°
        text = re.sub(r'<[^>]+>', '', text)

        # URL ì œê±°
        text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)

        # ì´ë©”ì¼ ì œê±°
        text = re.sub(r'\S+@\S+', '', text)

        # ê³¼ë„í•œ ê³µë°± ì •ë¦¬ (í•˜ì§€ë§Œ ì˜ë¯¸ìˆëŠ” ë„ì–´ì“°ê¸°ëŠ” ë³´ì¡´)
        text = re.sub(r'\s+', ' ', text)

        # ë¶ˆí•„ìš”í•œ íŠ¹ìˆ˜ë¬¸ì ì œê±° (ë³´ì¡´í•  ê²ƒë“¤ì€ ì œì™¸)
        if self.preserve_expressions:
            # ë³´ì¡´í•  íŠ¹ìˆ˜ë¬¸ì íŒ¨í„´ ìƒì„±
            preserve_chars = r'[ã…‹ã…ã… ã…œ\^!~â™¥â¤ğŸ’•â£ï¸\?\.]'
            # ë³´ì¡´í•  ë¬¸ìê°€ ì•„ë‹Œ íŠ¹ìˆ˜ë¬¸ìë§Œ ì œê±°
            unwanted_chars = r'[^\w\sê°€-í£ã…‹ã…ã… ã…œ\^!~â™¥â¤ğŸ’•â£ï¸\?\.,]'
            text = re.sub(unwanted_chars, ' ', text)
        else:
            # ëª¨ë“  íŠ¹ìˆ˜ë¬¸ì ì œê±°
            text = re.sub(r'[^\w\sê°€-í£]', ' ', text)

        return text.strip()

    def _normalize_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì •ê·œí™”"""
        # ì¤„ì„ë§ ì •ê·œí™”
        normalizations = {
            r'\bë„˜\b': 'ë„ˆë¬´',
            r'\bì§±\b': 'ì •ë§',
            r'\bê°œ\s*ë§›ìˆ': 'ì •ë§ ë§›ìˆ',
            r'\bì™„ì „\b': 'ì •ë§',
            r'\bì˜¤ì§œ\b': 'ì˜¤ì§•ì–´ì§œê¸€ì´',
            r'\bë–¡ë³¶ì´\b': 'ë–¡ë³¶ì´',
            r'\bì«„ë©´\b': 'ì«„ë©´'
        }

        normalized = text
        for pattern, replacement in normalizations.items():
            normalized = re.sub(pattern, replacement, normalized, flags=re.IGNORECASE)

        # ì¤‘ë³µ ë¬¸ì ì •ë¦¬ (ì˜ë¯¸ìˆëŠ” ê²ƒì€ ë³´ì¡´)
        if self.preserve_expressions:
            # ã…‹ã…‹ã…‹, ^^^ ë“±ì€ ë³´ì¡´í•˜ê³  ì¼ë°˜ ì¤‘ë³µë§Œ ì •ë¦¬
            normalized = re.sub(r'([ê°€-í£])\1{2,}', r'\1\1', normalized)  # í•œê¸€ 2ê¸€ìê¹Œì§€ë§Œ
        else:
            normalized = re.sub(r'(.)\1{2,}', r'\1', normalized)

        return normalized.strip()

    def _extract_keywords(self, text: str) -> List[str]:
        """í‚¤ì›Œë“œ ì¶”ì¶œ"""
        keywords = []
        text_lower = text.lower()

        # ìŒì‹ ê´€ë ¨ í‚¤ì›Œë“œ ì¶”ì¶œ
        for category, words in self.food_keywords.items():
            for word in words:
                if word in text_lower:
                    keywords.append(f"{category}:{word}")

        # ì˜ˆì‚° í‚¤ì›Œë“œ ì¶”ì¶œ
        budget_matches = []
        for pattern in self.budget_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            budget_matches.extend(matches)

        if budget_matches:
            for match in budget_matches:
                keywords.append(f"budget:{match}")

        # ë™ë°˜ì í‚¤ì›Œë“œ ì¶”ì¶œ
        companion_matches = []
        for pattern in self.companion_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                companion_matches.append(pattern)

        if companion_matches:
            for match in companion_matches:
                keywords.append(f"companion:{match}")

        # ì¤‘ë³µ ì œê±°
        return list(set(keywords))

    def _analyze_emotion(self, text: str, preserved_expressions: List[str]) -> Tuple[EmotionType, float]:
        """ê°ì • ë¶„ì„"""
        text_lower = text.lower()
        emotion_scores = {emotion: 0 for emotion in EmotionType}

        # í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì • ì ìˆ˜ ê³„ì‚°
        for emotion, keywords in self.emotion_keywords.items():
            for keyword in keywords:
                if keyword in text_lower:
                    emotion_scores[emotion] += 1

        # ë³´ì¡´ëœ í‘œí˜„ìœ¼ë¡œ ê°ì • ë³´ì •
        for expr in preserved_expressions:
            if expr.startswith('laughter:'):
                emotion_scores[EmotionType.POSITIVE] += 2
                emotion_scores[EmotionType.EXCITED] += 1
            elif expr.startswith('excitement:'):
                emotion_scores[EmotionType.EXCITED] += 2
                emotion_scores[EmotionType.POSITIVE] += 1
            elif expr.startswith('sadness:'):
                emotion_scores[EmotionType.NEGATIVE] += 2
                emotion_scores[EmotionType.DISAPPOINTED] += 1
            elif expr.startswith('heart:'):
                emotion_scores[EmotionType.POSITIVE] += 3

        # ìµœê³  ì ìˆ˜ ê°ì • ì„ íƒ
        max_emotion = max(emotion_scores, key=emotion_scores.get)
        max_score = emotion_scores[max_emotion]

        # ì‹ ë¢°ë„ ê³„ì‚° (ì ìˆ˜ / ì´ ê°€ëŠ¥ ì ìˆ˜)
        total_score = sum(emotion_scores.values())
        confidence = max_score / max(total_score, 1)

        # ì ìˆ˜ê°€ 0ì´ë©´ ì¤‘ë¦½
        if max_score == 0:
            return EmotionType.NEUTRAL, 0.0

        return max_emotion, min(confidence, 1.0)

    def extract_budget_info(self, text: str) -> Optional[int]:
        """ì˜ˆì‚° ì •ë³´ ì¶”ì¶œ (ì› ë‹¨ìœ„)"""
        text = text.replace(',', '').replace(' ', '')

        # ì› ë‹¨ìœ„ ì§ì ‘ í‘œí˜„
        won_pattern = r'(\d+)\s*ì›'
        won_matches = re.findall(won_pattern, text)
        if won_matches:
            return int(won_matches[0])

        # ì²œì› ë‹¨ìœ„
        thousand_pattern = r'(\d+)\s*ì²œ\s*ì›?'
        thousand_matches = re.findall(thousand_pattern, text)
        if thousand_matches:
            return int(thousand_matches[0]) * 1000

        # ë§Œì› ë‹¨ìœ„
        man_pattern = r'(\d+)\s*ë§Œ\s*ì›?'
        man_matches = re.findall(man_pattern, text)
        if man_matches:
            return int(man_matches[0]) * 10000

        return None

    def extract_companions(self, text: str) -> List[str]:
        """ë™ë°˜ì ì •ë³´ ì¶”ì¶œ"""
        companions = []
        text_lower = text.lower()

        companion_mapping = {
            'ì¹œêµ¬': 'friend',
            'ê°€ì¡±': 'family',
            'ì—„ë§ˆ': 'mother',
            'ì•„ë¹ ': 'father',
            'ë¶€ëª¨': 'parents',
            'í˜•': 'brother',
            'ëˆ„ë‚˜': 'sister',
            'ì–¸ë‹ˆ': 'sister',
            'ì˜¤ë¹ ': 'brother',
            'ë™ìƒ': 'sibling',
            'í˜¼ì': 'alone',
            'ì• ì¸': 'partner',
            'ë‚¨ì¹œ': 'boyfriend',
            'ì—¬ì¹œ': 'girlfriend'
        }

        for korean, english in companion_mapping.items():
            if korean in text_lower:
                companions.append(english)

        return list(set(companions))

    def clean_for_model_input(self, text: str) -> str:
        """ëª¨ë¸ ì…ë ¥ìš© í…ìŠ¤íŠ¸ ì •ì œ"""
        # ê¸°ë³¸ ì „ì²˜ë¦¬
        result = self.preprocess(text)

        # ëª¨ë¸ ì…ë ¥ì— ì í•©í•˜ê²Œ ì¶”ê°€ ì •ì œ
        cleaned = result.normalized_text

        # ìµœëŒ€ ê¸¸ì´ ì œí•œ
        if len(cleaned) > 200:
            cleaned = cleaned[:200].rsplit(' ', 1)[0]  # ë‹¨ì–´ ë‹¨ìœ„ë¡œ ìë¥´ê¸°

        # ë¹ˆ ë¬¸ìì—´ ì²˜ë¦¬
        if not cleaned.strip():
            cleaned = "ìŒì‹ ì¶”ì²œ ìš”ì²­"

        return cleaned

    def is_food_related(self, text: str) -> Tuple[bool, float]:
        """ìŒì‹ ê´€ë ¨ í…ìŠ¤íŠ¸ì¸ì§€ íŒë‹¨"""
        keywords = self._extract_keywords(text.lower())

        food_keywords = [k for k in keywords if k.startswith(('categories:', 'foods:', 'tastes:', 'cooking_methods:'))]

        # ìŒì‹ í‚¤ì›Œë“œ ë¹„ìœ¨ë¡œ ì‹ ë¢°ë„ ê³„ì‚°
        total_keywords = len(keywords)
        food_keyword_count = len(food_keywords)

        if total_keywords == 0:
            return False, 0.0

        confidence = food_keyword_count / total_keywords
        is_food_related = confidence > 0.3  # 30% ì´ìƒì´ë©´ ìŒì‹ ê´€ë ¨

        return is_food_related, confidence

    def get_preprocessing_summary(self, result: PreprocessResult) -> str:
        """ì „ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½"""
        return f"""
ì „ì²˜ë¦¬ ê²°ê³¼:
- ì›ë³¸: {result.original_text[:50]}...
- ì •ì œ: {result.cleaned_text[:50]}...
- í‚¤ì›Œë“œ: {len(result.extracted_keywords)}ê°œ
- ê°ì •: {result.emotion.value} ({result.confidence:.2f})
- ë³´ì¡´í‘œí˜„: {len(result.preserved_expressions)}ê°œ
"""


# í¸ì˜ í•¨ìˆ˜ë“¤
def quick_preprocess(text: str, preserve_expressions: bool = True) -> PreprocessResult:
    """ë¹ ë¥¸ ì „ì²˜ë¦¬ (í¸ì˜ í•¨ìˆ˜)"""
    preprocessor = NaviyamTextPreprocessor(preserve_expressions)
    return preprocessor.preprocess(text)


def extract_food_intent(text: str) -> Dict[str, any]:
    """ìŒì‹ ê´€ë ¨ ì˜ë„ ì¶”ì¶œ (í¸ì˜ í•¨ìˆ˜)"""
    preprocessor = NaviyamTextPreprocessor()
    result = preprocessor.preprocess(text)

    return {
        "is_food_related": preprocessor.is_food_related(text)[0],
        "budget": preprocessor.extract_budget_info(text),
        "companions": preprocessor.extract_companions(text),
        "emotion": result.emotion.value,
        "keywords": result.extracted_keywords
    }
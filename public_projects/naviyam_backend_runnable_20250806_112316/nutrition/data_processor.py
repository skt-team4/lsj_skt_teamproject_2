"""
ì˜ì–‘ì •ë³´ ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
APIë¡œë¶€í„° ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ì •ì œí•˜ê³  RAG ì‹œìŠ¤í…œìš©ìœ¼ë¡œ ë³€í™˜
"""

import pandas as pd
import numpy as np
import logging
import json
from typing import List, Dict, Any, Optional, Tuple
from pathlib import Path
from datetime import datetime
import re
from dataclasses import asdict

from .api_client import NutritionInfo, FoodSafetyAPIClient

logger = logging.getLogger(__name__)


class NutritionDataProcessor:
    """ì˜ì–‘ì •ë³´ ë°ì´í„° ì „ì²˜ë¦¬ê¸°"""
    
    def __init__(self, output_dir: str = "outputs/nutrition"):
        """
        ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
        
        Args:
            output_dir: ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ ê²½ë¡œ
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # í•œêµ­ì–´ ìŒì‹ëª… ì •ê·œí™”ë¥¼ ìœ„í•œ íŒ¨í„´
        self.food_name_patterns = {
            # ê³µí†µ ë‹¨ì–´ ì œê±°
            'remove_patterns': [r'\([^)]*\)', r'\[[^\]]*\]', r'ìƒê²ƒ', r'ìµíŒê²ƒ', r'ì¡°ë¦¬ëœê²ƒ'],
            # ë™ì˜ì–´ ë§¤í•‘
            'synonyms': {
                'ë‹­ê³ ê¸°': ['ì¹˜í‚¨', 'ê³„ìœ¡'],
                'ë¼ì§€ê³ ê¸°': ['ëˆìœ¡', 'í¬í¬'],
                'ì†Œê³ ê¸°': ['ìš°ìœ¡', 'ë¹„í”„'],
                'ê¹€ì¹˜': ['ë°°ì¶”ê¹€ì¹˜', 'í¬ê¸°ê¹€ì¹˜'],
                'ë°¥': ['ìŒ€ë°¥', 'ë°±ë¯¸ë°¥'],
                'êµ­ìˆ˜': ['ë©´', 'ëˆ„ë“¤']
            }
        }
    
    def clean_nutrition_data(self, nutrition_list: List[NutritionInfo]) -> pd.DataFrame:
        """
        ì˜ì–‘ì •ë³´ ë°ì´í„° ì •ì œ
        
        Args:
            nutrition_list: ì›ë³¸ ì˜ì–‘ì •ë³´ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ì •ì œëœ DataFrame
        """
        logger.info(f"Starting data cleaning for {len(nutrition_list)} items")
        
        # DataFrame ë³€í™˜
        df = pd.DataFrame([asdict(info) for info in nutrition_list])
        
        if df.empty:
            logger.warning("Empty dataset provided")
            return df
        
        original_count = len(df)
        
        # 1. ê¸°ë³¸ ì •ì œ
        df = self._basic_cleaning(df)
        
        # 2. ìŒì‹ëª… ì •ê·œí™”
        df = self._normalize_food_names(df)
        
        # 3. ì˜ì–‘ì„±ë¶„ ë°ì´í„° ì •ì œ
        df = self._clean_nutrition_values(df)
        
        # 4. ì¤‘ë³µ ì œê±°
        df = self._remove_duplicates(df)
        
        # 5. ì´ìƒì¹˜ ì²˜ë¦¬
        df = self._handle_outliers(df)
        
        # 6. ì•„ë™ ì¹œí™”ì  ì¹´í…Œê³ ë¦¬ ì¶”ê°€
        df = self._add_child_friendly_categories(df)
        
        cleaned_count = len(df)
        logger.info(f"Data cleaning completed: {original_count} â†’ {cleaned_count} items")
        
        return df
    
    def _basic_cleaning(self, df: pd.DataFrame) -> pd.DataFrame:
        """ê¸°ë³¸ ë°ì´í„° ì •ì œ"""
        logger.info("Performing basic data cleaning...")
        
        # í•„ìˆ˜ ì»¬ëŸ¼ ì²´í¬
        required_columns = ['food_name', 'calories', 'carbohydrate', 'protein', 'fat']
        missing_cols = [col for col in required_columns if col not in df.columns]
        if missing_cols:
            raise ValueError(f"Missing required columns: {missing_cols}")
        
        # ë¹ˆ ìŒì‹ëª… ì œê±°
        df = df[df['food_name'].notna() & (df['food_name'].str.strip() != '')]
        
        # ìŒì‹ëª… ê¸°ë³¸ ì •ì œ
        df['food_name'] = df['food_name'].str.strip()
        df['food_name_clean'] = df['food_name'].copy()
        
        # ì¹´í…Œê³ ë¦¬ ì •ì œ
        df['category'] = df['category'].fillna('ê¸°íƒ€').str.strip()
        
        return df
    
    def _normalize_food_names(self, df: pd.DataFrame) -> pd.DataFrame:
        """ìŒì‹ëª… ì •ê·œí™”"""
        logger.info("Normalizing food names...")
        
        def normalize_name(name: str) -> str:
            if pd.isna(name):
                return name
            
            # ê´„í˜¸, ëŒ€ê´„í˜¸ ë‚´ìš© ì œê±°
            for pattern in self.food_name_patterns['remove_patterns']:
                name = re.sub(pattern, '', name)
            
            # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ
            name = re.sub(r'\s+', ' ', name).strip()
            
            return name
        
        df['food_name_normalized'] = df['food_name_clean'].apply(normalize_name)
        
        # ë™ì˜ì–´ ë§¤í•‘ ì ìš©
        for standard, synonyms in self.food_name_patterns['synonyms'].items():
            for synonym in synonyms:
                mask = df['food_name_normalized'].str.contains(synonym, na=False)
                df.loc[mask, 'food_name_standardized'] = df.loc[mask, 'food_name_normalized'].str.replace(synonym, standard)
        
        # í‘œì¤€í™”ëœ ì´ë¦„ì´ ì—†ìœ¼ë©´ ì •ê·œí™”ëœ ì´ë¦„ ì‚¬ìš©
        df['food_name_standardized'] = df.get('food_name_standardized', df['food_name_normalized'])
        
        return df
    
    def _clean_nutrition_values(self, df: pd.DataFrame) -> pd.DataFrame:
        """ì˜ì–‘ì„±ë¶„ ê°’ ì •ì œ"""
        logger.info("Cleaning nutrition values...")
        
        nutrition_columns = ['calories', 'carbohydrate', 'protein', 'fat', 'sugar', 
                           'sodium', 'cholesterol', 'saturated_fat', 'trans_fat']
        
        for col in nutrition_columns:
            if col in df.columns:
                # 0 ë¯¸ë§Œ ê°’ì„ 0ìœ¼ë¡œ ë³€ê²½
                df[col] = df[col].clip(lower=0)
                
                # ê·¹ë‹¨ì ì¸ ì´ìƒì¹˜ ì²˜ë¦¬ (99.9 ë°±ë¶„ìœ„ìˆ˜ ê¸°ì¤€)
                if col in ['calories']:
                    upper_limit = df[col].quantile(0.999)
                    df[col] = df[col].clip(upper=upper_limit)
        
        # ê¸°ë³¸ ì˜ì–‘ì„±ë¶„ì´ ëª¨ë‘ 0ì¸ í•­ëª© ì œê±°
        essential_nutrients = ['calories', 'carbohydrate', 'protein', 'fat']
        zero_mask = (df[essential_nutrients] == 0).all(axis=1)
        df = df[~zero_mask]
        
        return df
    
    def _remove_duplicates(self, df: pd.DataFrame) -> pd.DataFrame:
        """ì¤‘ë³µ ë°ì´í„° ì œê±°"""
        logger.info("Removing duplicates...")
        
        original_count = len(df)
        
        # ìŒì‹ëª…ê³¼ ì£¼ìš” ì˜ì–‘ì„±ë¶„ ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±°
        duplicate_columns = ['food_name_standardized', 'calories', 'protein', 'carbohydrate', 'fat']
        df = df.drop_duplicates(subset=duplicate_columns, keep='first')
        
        removed_count = original_count - len(df)
        if removed_count > 0:
            logger.info(f"Removed {removed_count} duplicate entries")
        
        return df
    
    def _handle_outliers(self, df: pd.DataFrame) -> pd.DataFrame:
        """ì´ìƒì¹˜ ì²˜ë¦¬"""
        logger.info("Handling outliers...")
        
        # ì¹¼ë¡œë¦¬ ê¸°ì¤€ ì´ìƒì¹˜ ê²€ì¶œ (IQR ë°©ë²•)
        Q1 = df['calories'].quantile(0.25)
        Q3 = df['calories'].quantile(0.75)
        IQR = Q3 - Q1
        
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        # ê·¹ë‹¨ì ì¸ ì´ìƒì¹˜ë§Œ ì œê±° (3 IQR ê¸°ì¤€)
        extreme_lower = Q1 - 3 * IQR
        extreme_upper = Q3 + 3 * IQR
        
        outlier_mask = (df['calories'] < extreme_lower) | (df['calories'] > extreme_upper)
        outlier_count = outlier_mask.sum()
        
        if outlier_count > 0:
            logger.warning(f"Removing {outlier_count} extreme outliers")
            df = df[~outlier_mask]
        
        return df
    
    def _add_child_friendly_categories(self, df: pd.DataFrame) -> pd.DataFrame:
        """ì•„ë™ ì¹œí™”ì  ì¹´í…Œê³ ë¦¬ ì¶”ê°€"""
        logger.info("Adding child-friendly categories...")
        
        def categorize_for_children(row):
            """ì•„ë™ìš© ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
            food_name = str(row['food_name_standardized']).lower()
            category = str(row['category']).lower()
            
            # ê³¼ì¼
            if any(fruit in food_name for fruit in ['ì‚¬ê³¼', 'ë°”ë‚˜ë‚˜', 'ë”¸ê¸°', 'í¬ë„', 'ì˜¤ë Œì§€', 'í‚¤ìœ„', 'ìˆ˜ë°•', 'ì°¸ì™¸']):
                return 'ê±´ê°•í•œ ê³¼ì¼'
            
            # ì±„ì†Œ
            elif any(veg in food_name for veg in ['ë‹¹ê·¼', 'ë¸Œë¡œì½œë¦¬', 'ì‹œê¸ˆì¹˜', 'ë°°ì¶”', 'ë¬´', 'ì–‘ë°°ì¶”']):
                return 'ëª¸ì— ì¢‹ì€ ì±„ì†Œ'
            
            # ë°¥ë¥˜
            elif any(rice in food_name for rice in ['ë°¥', 'ë¹„ë¹”ë°¥', 'ë³¶ìŒë°¥', 'ê¹€ë°¥']):
                return 'ë“ ë“ í•œ ë°¥'
            
            # ë©´ë¥˜
            elif any(noodle in food_name for noodle in ['ë©´', 'êµ­ìˆ˜', 'ë¼ë©´', 'íŒŒìŠ¤íƒ€', 'ìš°ë™', 'ëƒ‰ë©´']):
                return 'ë§›ìˆëŠ” ë©´'
            
            # ê³ ê¸°ë¥˜
            elif any(meat in food_name for meat in ['ê³ ê¸°', 'ì¹˜í‚¨', 'ë¶ˆê³ ê¸°', 'ê°ˆë¹„', 'ì‚¼ê²¹ì‚´']):
                return 'í˜ì´ ë‚˜ëŠ” ê³ ê¸°'
            
            # ìƒì„ ë¥˜
            elif any(fish in food_name for fish in ['ìƒì„ ', 'ê³ ë“±ì–´', 'ì—°ì–´', 'ì°¸ì¹˜', 'ëª…íƒœ']):
                return 'ì˜ì–‘ ë§Œì  ìƒì„ '
            
            # êµ­ë¬¼ë¥˜
            elif any(soup in food_name for soup in ['êµ­', 'ì°Œê°œ', 'íƒ•', 'ìŠ¤í”„']):
                return 'ë”°ëœ»í•œ êµ­ë¬¼'
            
            # ê°„ì‹ë¥˜
            elif any(snack in food_name for snack in ['ê³¼ì', 'ì¼€ì´í¬', 'ì¿ í‚¤', 'ì‚¬íƒ•', 'ì´ˆì½œë¦¿']):
                return 'ë‹¬ì½¤í•œ ê°„ì‹'
            
            # ìŒë£Œ
            elif any(drink in food_name for drink in ['ìŒë£Œ', 'ì£¼ìŠ¤', 'ìš°ìœ ', 'ìš”êµ¬ë¥´íŠ¸']):
                return 'ì‹œì›í•œ ìŒë£Œ'
            
            else:
                return 'ê¸°íƒ€ ìŒì‹'
        
        df['child_category'] = df.apply(categorize_for_children, axis=1)
        
        # ê±´ê°•ë„ ì ìˆ˜ ì¶”ê°€ (5ì  ë§Œì )
        def calculate_health_score(row):
            """ê°„ë‹¨í•œ ê±´ê°•ë„ ì ìˆ˜ ê³„ì‚°"""
            score = 3.0  # ê¸°ë³¸ ì ìˆ˜
            
            # ë‹¨ë°±ì§ˆ ë¹„ìœ¨ì´ ë†’ìœ¼ë©´ ê°€ì 
            if row['protein'] > 15:
                score += 0.5
            
            # ë‚˜íŠ¸ë¥¨ì´ ì ìœ¼ë©´ ê°€ì 
            if row['sodium'] < 500:
                score += 0.5
            
            # ë‹¹ë¶„ì´ ë§ìœ¼ë©´ ê°ì 
            if row['sugar'] > 20:
                score -= 0.5
            
            # í¬í™”ì§€ë°©ì´ ë§ìœ¼ë©´ ê°ì 
            if row['saturated_fat'] > 10:
                score -= 0.5
            
            return max(1.0, min(5.0, score))
        
        df['health_score'] = df.apply(calculate_health_score, axis=1)
        
        return df
    
    def create_search_text(self, df: pd.DataFrame) -> pd.DataFrame:
        """ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ ìƒì„±"""
        logger.info("Creating search text for RAG...")
        
        def generate_search_text(row):
            """RAG ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ ìƒì„±"""
            parts = []
            
            # ê¸°ë³¸ ì •ë³´
            parts.append(f"ìŒì‹ëª…: {row['food_name_standardized']}")
            parts.append(f"ì¹´í…Œê³ ë¦¬: {row['child_category']}")
            
            # ì˜ì–‘ ì •ë³´ (ì•„ë™ ì¹œí™”ì  í‘œí˜„)
            parts.append(f"ì¹¼ë¡œë¦¬: {row['calories']:.0f}kcal")
            parts.append(f"ë‹¨ë°±ì§ˆ: {row['protein']:.1f}g (ê·¼ìœ¡ì„ ë§Œë“¤ì–´ì¤˜ìš”)")
            parts.append(f"íƒ„ìˆ˜í™”ë¬¼: {row['carbohydrate']:.1f}g (ì—ë„ˆì§€ë¥¼ ì¤˜ìš”)")
            parts.append(f"ì§€ë°©: {row['fat']:.1f}g")
            
            if row['sugar'] > 0:
                parts.append(f"ë‹¹ë¶„: {row['sugar']:.1f}g")
            
            if row['sodium'] > 0:
                parts.append(f"ë‚˜íŠ¸ë¥¨: {row['sodium']:.0f}mg")
            
            # ê±´ê°•ë„ ì ìˆ˜
            parts.append(f"ê±´ê°•ë„: {row['health_score']:.1f}/5ì ")
            
            # ì•„ë™ìš© ì„¤ëª… ì¶”ê°€
            if row['health_score'] >= 4.0:
                parts.append("ì˜ì–‘ì´ í’ë¶€í•´ì„œ ìì£¼ ë¨¹ìœ¼ë©´ ì¢‹ì•„ìš”!")
            elif row['health_score'] >= 3.0:
                parts.append("ì ë‹¹íˆ ë¨¹ìœ¼ë©´ ë§›ìˆê³  ê±´ê°•í•´ìš”!")
            else:
                parts.append("ê°€ë” ë¨¹ëŠ” ê²Œ ì¢‹ì•„ìš”!")
            
            return " | ".join(parts)
        
        df['search_text'] = df.apply(generate_search_text, axis=1)
        
        return df
    
    def save_processed_data(self, df: pd.DataFrame, 
                          filename: str = "processed_nutrition_data") -> Tuple[str, str]:
        """
        ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥
        
        Args:
            df: ì²˜ë¦¬ëœ DataFrame
            filename: ì €ì¥í•  íŒŒì¼ëª… (í™•ì¥ì ì œì™¸)
            
        Returns:
            (parquet_path, json_path) ì €ì¥ëœ íŒŒì¼ ê²½ë¡œë“¤
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Parquet íŒŒì¼ë¡œ ì €ì¥ (íš¨ìœ¨ì ì¸ ë°ì´í„° ì €ì¥)
        parquet_path = self.output_dir / f"{filename}_{timestamp}.parquet"
        df.to_parquet(parquet_path, index=False)
        
        # JSON íŒŒì¼ë¡œë„ ì €ì¥ (í˜¸í™˜ì„±)
        json_path = self.output_dir / f"{filename}_{timestamp}.json"
        df.to_json(json_path, orient='records', force_ascii=False, indent=2)
        
        # ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata = {
            'created_at': datetime.now().isoformat(),
            'total_items': len(df),
            'columns': list(df.columns),
            'categories': df['child_category'].value_counts().to_dict(),
            'avg_health_score': float(df['health_score'].mean()),
            'parquet_file': str(parquet_path),
            'json_file': str(json_path)
        }
        
        metadata_path = self.output_dir / f"{filename}_{timestamp}_metadata.json"
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        logger.info(f"Processed data saved to:")
        logger.info(f"  - Parquet: {parquet_path}")
        logger.info(f"  - JSON: {json_path}")
        logger.info(f"  - Metadata: {metadata_path}")
        
        return str(parquet_path), str(json_path)
    
    def get_statistics(self, df: pd.DataFrame) -> Dict[str, Any]:
        """ì²˜ë¦¬ëœ ë°ì´í„° í†µê³„ ë°˜í™˜"""
        if df.empty:
            return {}
        
        stats = {
            'total_items': len(df),
            'categories': df['child_category'].value_counts().to_dict(),
            'nutrition_stats': {
                'avg_calories': float(df['calories'].mean()),
                'avg_protein': float(df['protein'].mean()),
                'avg_carbs': float(df['carbohydrate'].mean()),
                'avg_fat': float(df['fat'].mean()),
                'avg_health_score': float(df['health_score'].mean())
            },
            'top_healthy_foods': df.nlargest(10, 'health_score')[['food_name_standardized', 'health_score']].to_dict('records'),
            'sample_search_texts': df['search_text'].head(3).tolist()
        }
        
        return stats


def process_nutrition_data_pipeline(api_key: str, 
                                  max_items: Optional[int] = 1000,
                                  output_dir: str = "outputs/nutrition") -> Dict[str, Any]:
    """
    ì „ì²´ ì˜ì–‘ì •ë³´ ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    
    Args:
        api_key: ì‹í’ˆì•ˆì „ì²˜ API í‚¤
        max_items: ìˆ˜ì§‘í•  ìµœëŒ€ ë°ì´í„° ìˆ˜
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        
    Returns:
        ì²˜ë¦¬ ê²°ê³¼ ì •ë³´
    """
    try:
        # 1. ë°ì´í„° ìˆ˜ì§‘
        logger.info("Step 1: Collecting nutrition data from API...")
        client = FoodSafetyAPIClient(api_key)
        nutrition_data = client.get_all_nutrition_data(max_items=max_items)
        
        if not nutrition_data:
            raise ValueError("No nutrition data collected from API")
        
        # 2. ë°ì´í„° ì „ì²˜ë¦¬
        logger.info("Step 2: Processing nutrition data...")
        processor = NutritionDataProcessor(output_dir)
        processed_df = processor.clean_nutrition_data(nutrition_data)
        
        # 3. ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ ìƒì„±
        logger.info("Step 3: Creating search text...")
        processed_df = processor.create_search_text(processed_df)
        
        # 4. ë°ì´í„° ì €ì¥
        logger.info("Step 4: Saving processed data...")
        parquet_path, json_path = processor.save_processed_data(processed_df)
        
        # 5. í†µê³„ ìƒì„±
        stats = processor.get_statistics(processed_df)
        
        result = {
            'status': 'success',
            'processed_items': len(processed_df),
            'parquet_file': parquet_path,
            'json_file': json_path,
            'statistics': stats
        }
        
        logger.info("Nutrition data processing pipeline completed successfully!")
        return result
        
    except Exception as e:
        logger.error(f"Error in nutrition data processing pipeline: {e}")
        return {
            'status': 'error',
            'error': str(e)
        }


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    import sys
    
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python data_processor.py <API_KEY> [max_items]")
        sys.exit(1)
    
    api_key = sys.argv[1]
    max_items = int(sys.argv[2]) if len(sys.argv) > 2 else 100
    
    result = process_nutrition_data_pipeline(api_key, max_items)
    
    if result['status'] == 'success':
        print(f"âœ… ì²˜ë¦¬ ì™„ë£Œ: {result['processed_items']}ê°œ í•­ëª©")
        print(f"ğŸ“ íŒŒì¼ ì €ì¥: {result['parquet_file']}")
    else:
        print(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {result['error']}")
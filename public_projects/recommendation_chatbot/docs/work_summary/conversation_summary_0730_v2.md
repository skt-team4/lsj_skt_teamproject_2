# ë‚˜ë¹„ì–Œ ì±—ë´‡ ê°œë°œ ëŒ€í™” ìš”ì•½ - 2025.07.30 (v2)

*ì´ì „ ì„¸ì…˜ ìš”ì•½: [conversation_summary_0729_v0.md](conversation_summary_0729_v0.md)*  
*v1 ì—…ë°ì´íŠ¸: [conversation_summary_0730_v1.md](conversation_summary_0730_v1.md)*

## ğŸ¯ 2025.07.30 ì„¸ì…˜ ì£¼ìš” í™œë™ (v2 ì—…ë°ì´íŠ¸)

### 25-43. **[v1 ê¸°ì¡´ ë‚´ìš© ìœ ì§€]** âœ…

*v1ì—ì„œ ì™„ì„±ëœ ëª¨ë“  ë‚´ìš© (Gemini-Claude í˜‘ë ¥, í”„ë¡œì íŠ¸ êµ¬ì¡° ë¶„ì„, ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ ì„¤ê³„, Layer 1+2 ì™„ì „ êµ¬í˜„)ì€ ê·¸ëŒ€ë¡œ ìœ ì§€*

---

## ğŸ†• **v2 ì‹ ê·œ ì¶”ê°€: í•™ìŠµ ë° ìš´ì˜ ì™„ì „ ê°€ì´ë“œ** âœ…

### 44. **ğŸ¤– ì±—ë´‡ í•™ìŠµ ë°ì´í„° êµ¬ì¡° ë° í”„ë¡œì„¸ìŠ¤** âœ…

#### **ì±—ë´‡ì˜ ì—­í•  ì •ì˜**
- **NLU (ìì—°ì–´ ì´í•´)**: ì‚¬ìš©ì ì…ë ¥ â†’ ì˜ë„(Intent) + êµ¬ì¡°í™”ëœ ì •ë³´ ì¶”ì¶œ
- **NLG (ìì—°ì–´ ìƒì„±)**: ì¶”ì²œ ê²°ê³¼ â†’ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”í˜• ì‘ë‹µ ìƒì„±
- **LoRA íŒŒì¸íŠœë‹**: SKT A.X-3.1-Light â†’ ìŒì‹ ë„ë©”ì¸ íŠ¹í™”

#### **A. NLU í•™ìŠµ ë°ì´í„° êµ¬ì¡°**
```json
{
  "training_data": [
    {
      "text": "ì•„ì´ë‘ ê°ˆë§Œí•œ ê±´ê°•í•œ ì €ë… ì‹ë‹¹ ì¶”ì²œí•´ì¤˜",
      "intent": "FOOD_RECOMMENDATION",
      "entities": [
        {"entity": "companion", "value": "ì•„ì´", "start": 0, "end": 2},
        {"entity": "dietary_preference", "value": "ê±´ê°•í•œ", "start": 6, "end": 9},
        {"entity": "time_of_day", "value": "ì €ë…", "start": 12, "end": 14}
      ],
      "semantic_query": "ê°€ì¡± ê±´ê°•ì‹ ì €ë… ì‹ë‹¹",
      "filters": {
        "dietary_preferences": ["ê±´ê°•ì‹"],
        "companion": "family",
        "time_of_day": "dinner"
      }
    },
    {
      "text": "ë§Œì›ìœ¼ë¡œ ì¹˜í‚¨ ë¨¹ì„ ìˆ˜ ìˆëŠ” ê³³ ìˆì–´?", 
      "intent": "BUDGET_FOOD_INQUIRY",
      "entities": [
        {"entity": "budget", "value": "10000", "start": 0, "end": 2},
        {"entity": "food_type", "value": "ì¹˜í‚¨", "start": 4, "end": 6}
      ],
      "semantic_query": "ì¹˜í‚¨",
      "filters": {
        "budget_filter": 10000,
        "category": "ì¹˜í‚¨"
      }
    }
  ]
}
```

#### **B. NLG í•™ìŠµ ë°ì´í„° êµ¬ì¡°**
```json
{
  "response_templates": [
    {
      "intent": "FOOD_RECOMMENDATION", 
      "recommendation_count": 3,
      "template": "{shop_name}ì€ {reason}ë¡œ ì¶”ì²œë“œë ¤ìš”! {special_feature}",
      "examples": [
        {
          "input": {
            "shop_name": "ê±´ê°•í•œì§‘",
            "reason": "ì•„ì´ì™€ í•¨ê»˜ ê°€ê¸° ì¢‹ê³  ê±´ê°•í•œ ë©”ë‰´",
            "special_feature": "ì°©í•œê°€ê²Œë¡œ ê°€ê²©ë„ í•©ë¦¬ì ì´ì—ìš”"
          },
          "output": "ê±´ê°•í•œì§‘ì€ ì•„ì´ì™€ í•¨ê»˜ ê°€ê¸° ì¢‹ê³  ê±´ê°•í•œ ë©”ë‰´ë¡œ ì¶”ì²œë“œë ¤ìš”! ì°©í•œê°€ê²Œë¡œ ê°€ê²©ë„ í•©ë¦¬ì ì´ì—ìš”"
        }
      ]
    }
  ]
}
```

#### **C. LoRA íŒŒì¸íŠœë‹ ë°ì´í„° êµ¬ì¡°**
```python
# training/lora_trainer.pyì—ì„œ ì‚¬ìš©í•˜ëŠ” ë°ì´í„° í˜•íƒœ
lora_training_data = [
    {
        "instruction": "ì‚¬ìš©ìì˜ ìŒì‹ ìš”ì²­ì„ ë¶„ì„í•˜ê³  ì ì ˆí•œ ê²€ìƒ‰ ì¡°ê±´ì„ ì¶”ì¶œí•˜ì„¸ìš”.",
        "input": "ì• ë“¤ì´ë‘ ê°€ì„œ ë§›ìˆê²Œ ë¨¹ì„ ìˆ˜ ìˆëŠ” í•œì‹ë‹¹ ì¶”ì²œí•´ì£¼ì„¸ìš”",
        "output": {
            "semantic_query": "ê°€ì¡± í•œì‹ë‹¹",
            "filters": {
                "category": "í•œì‹",
                "companion": "family",
                "atmosphere": "family_friendly"
            },
            "intent": "FOOD_RECOMMENDATION"
        }
    }
]

# nlp/llm_normalizer.pyì—ì„œ ì‚¬ìš©í•˜ëŠ” ì•„ë™ ì¹œí™”ì  ì‘ë‹µ í•™ìŠµ ë°ì´í„°
child_friendly_data = [
    {
        "original": "ì´ ì‹ë‹¹ì€ ë§¤ìš° í›Œë¥­í•œ ìŒì‹ì„ ì œê³µí•©ë‹ˆë‹¤.",
        "child_friendly": "ì´ ì‹ë‹¹ì€ ì •ë§ ë§›ìˆëŠ” ìŒì‹ì„ ë§Œë“¤ì–´ìš”! ğŸ˜Š"
    },
    {
        "original": "ì˜ˆì‚° ë²”ìœ„ë¥¼ ì´ˆê³¼í•˜ëŠ” ê°€ê²©ëŒ€ì…ë‹ˆë‹¤.",
        "child_friendly": "ì¡°ê¸ˆ ë¹„ì‹¸ì„œ ë‹¤ë¥¸ ê³³ì„ ì°¾ì•„ë³¼ê¹Œìš”?"
    }
]
```

#### **D. ì±—ë´‡ í•™ìŠµ ì‹¤í–‰ í”„ë¡œì„¸ìŠ¤**
```bash
# 1. NLU ëª¨ë¸ í•™ìŠµ
cd nlp/
python nlu.py --train --data ../data/nlu_training_data.json --epochs 10

# 2. LoRA íŒŒì¸íŠœë‹ ì‹¤í–‰
cd training/
python lora_trainer.py \
    --base_model "skt/A.X-3.1-Light" \
    --training_data ../data/lora_training_data.jsonl \
    --output_dir ../outputs/lora_models/ \
    --epochs 3 \
    --batch_size 4 \
    --learning_rate 0.0001

# 3. ì•„ë™ ì¹œí™”ì  ì‘ë‹µ ëª¨ë¸ í•™ìŠµ
cd nlp/
python llm_normalizer.py \
    --train \
    --data ../data/child_friendly_data.json \
    --model_path ../outputs/child_normalizer.pth

# 4. í†µí•© í…ŒìŠ¤íŠ¸
cd ../
python main.py --mode evaluation
```

#### **E. ì‹¤ì‹œê°„ í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘**
```python
# inference/data_collector.pyì—ì„œ ìˆ˜ì§‘í•˜ëŠ” ëŒ€í™” ë°ì´í„°
def collect_conversation_data():
    return {
        "timestamp": datetime.now().isoformat(),
        "user_id": user_id,
        "user_input": "ì‚¬ìš©ì ì›ë³¸ ì…ë ¥",
        "chatbot_analysis": {
            "semantic_query": "ì¶”ì¶œëœ ì˜ë¯¸ ì¿¼ë¦¬",
            "filters": {"category": "í•œì‹"},
            "intent": "FOOD_RECOMMENDATION",
            "confidence": 0.95
        },
        "final_response": "ì±—ë´‡ ìµœì¢… ì‘ë‹µ",
        "user_feedback": {
            "satisfaction_score": 4.5,  # 1-5ì 
            "selected_shop": "shop_id_001",
            "interaction_type": "clicked" | "ordered" | "favorited"
        }
    }

# ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ í•™ìŠµ í˜•íƒœë¡œ ë³€í™˜
def convert_to_training_data():
    conversations = load_conversation_logs()
    
    nlu_data = []
    lora_data = []
    
    for conv in conversations:
        if conv['user_feedback']['satisfaction_score'] >= 4.0:
            # ë§Œì¡±ë„ ë†’ì€ ëŒ€í™”ëŠ” í•™ìŠµ ë°ì´í„°ë¡œ í™œìš©
            nlu_data.append({
                "text": conv['user_input'],
                "intent": conv['chatbot_analysis']['intent'],
                "semantic_query": conv['chatbot_analysis']['semantic_query'],
                "filters": conv['chatbot_analysis']['filters']
            })
            
            lora_data.append({
                "instruction": "ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ê³  ê²€ìƒ‰ ì¡°ê±´ì„ ì¶”ì¶œí•˜ì„¸ìš”.",
                "input": conv['user_input'],
                "output": conv['chatbot_analysis']
            })
    
    save_training_data(nlu_data, lora_data)
```

### 45. **ğŸ¯ ì¶”ì²œì—”ì§„ í•™ìŠµ ë°ì´í„° êµ¬ì¡° ë° í”„ë¡œì„¸ìŠ¤** âœ…

#### **ì¶”ì²œì—”ì§„ì˜ ì—­í•  ì •ì˜**
- **Layer 1 í›„ë³´ ìƒì„±**: 4-Funnelë¡œ ë‹¤ì–‘í•œ í›„ë³´êµ° ìƒì„± (ì´ë¯¸ ì™„ì„±)
- **Layer 2 ê°œì¸í™” ë­í‚¹**: Wide & Deep ëª¨ë¸ë¡œ ì‚¬ìš©ìë³„ ìµœì  ìˆœìœ„ ê²°ì •
- **ì‹¤ì‹œê°„ í•™ìŠµ**: ì‚¬ìš©ì í”¼ë“œë°±ìœ¼ë¡œ ëª¨ë¸ ì§€ì† ê°œì„ 

#### **A. Wide & Deep ëª¨ë¸ í•™ìŠµ ë°ì´í„° êµ¬ì¡°**
```python
# recommendation/model_trainer.pyì—ì„œ ìƒì„±í•˜ëŠ” í›ˆë ¨ ìƒ˜í”Œ
training_sample = {
    # Wide Component Features (Cross-Product) - 50ì°¨ì›
    "wide_features": np.array([
        0.7,  # user_age_group(30s) Ã— shop_category(í•œì‹) í•´ì‹œê°’
        0.9,  # user_location(ì„œìš¸) Ã— shop_district(ê´€ì•…êµ¬) í•´ì‹œê°’  
        0.6,  # time_of_day(dinner) Ã— shop_category(í•œì‹) í•´ì‹œê°’
        0.8,  # user_id Ã— shop_id íŠ¹ë³„ ìƒí˜¸ì‘ìš©
        0.85, # budget_compatibility (ì˜ˆì‚° ì í•©ì„±)
        0.9,  # location_distance (ìœ„ì¹˜ ê±°ë¦¬)
        0.7,  # dietary_preference_match (ì‹ë‹¨ ì„ í˜¸)
        0.3,  # good_shop_feature (í¸í–¥ ë³´ì •ë¨: ì›ë˜ 1.0 â†’ 0.3)
        0.6,  # rating_feature (ì„ê³„ê°’ 3.5 ì ìš©)
        1.0, 0.0, 0.0, 1.0,  # Funnel í™œì„±í™” (collaborative, content, contextual, popularity)
        0.8, 0.0, 0.0, 0.7,  # Funnel ì ìˆ˜ë“¤ (ì •ê·œí™”ë¨)
        # ... ì´ 50ì°¨ì›ê¹Œì§€ 0.0ìœ¼ë¡œ íŒ¨ë”©
    ]),
    
    # Deep Component Features  
    "user_id": 863,                    # user.id â†’ 64ì°¨ì› ì„ë² ë”©
    "shop_id": "shop_001",             # shop.id â†’ 64ì°¨ì› ì„ë² ë”©
    "brand_id": "brand_korean_001",    # brand.id â†’ 16ì°¨ì› ì„ë² ë”©
    "category": "í•œì‹",                # shop.category â†’ 16ì°¨ì› ì„ë² ë”©
    "semantic_query": "ê°€ì¡± ì €ë… í•œì‹", # ì±—ë´‡ output â†’ 128ì°¨ì› ì„ë² ë”©
    
    "numerical_features": np.array([
        0.35,  # user_age (35ì„¸ / 100ìœ¼ë¡œ ì •ê·œí™”)
        0.16,  # user_favorite_count (8ê°œ / 50ìœ¼ë¡œ ì •ê·œí™”)
        0.25,  # user_total_orders (25ê°œ / 100ìœ¼ë¡œ ì •ê·œí™”)
        0.24,  # user_review_count (12ê°œ / 50ìœ¼ë¡œ ì •ê·œí™”)
        0.36,  # shop_avg_menu_price (18000ì› / 50000ìœ¼ë¡œ ì •ê·œí™”)
        0.67,  # shop_menu_count (20ê°œ / 30ìœ¼ë¡œ ì •ê·œí™”)
        0.84,  # shop_rating (4.2ì  / 5.0ìœ¼ë¡œ ì •ê·œí™”)
        0.15,  # shop_review_count (150ê°œ / 1000ìœ¼ë¡œ ì •ê·œí™”)
        0.08,  # shop_order_count (80ê°œ / 1000ìœ¼ë¡œ ì •ê·œí™”)
        0.5    # operating_hours (12ì‹œê°„ / 24ë¡œ ì •ê·œí™”)
    ]),
    
    # ë ˆì´ë¸” (ì‹¤ì œ ìƒí˜¸ì‘ìš© ê¸°ë¡ ê¸°ë°˜)
    "label": 1.0  # 1: ì£¼ë¬¸/ì¦ê²¨ì°¾ê¸°/ê³ í‰ì , 0: ë¯¸ì„ íƒ
}
```

#### **B. í›ˆë ¨ ë°ì´í„° ìƒì„± ìŠ¤í¬ë¦½íŠ¸**
```python
# recommendation/data_generator.py (ì‹ ê·œ ìƒì„± í•„ìš”)
def generate_training_data_from_db():
    """ì‹¤ì œ DB ì‹œíŠ¸ë“¤ì—ì„œ í›ˆë ¨ ë°ì´í„° ìƒì„±"""
    
    positive_samples = []
    negative_samples = []
    
    # 1. Positive ìƒ˜í”Œ: ì‹¤ì œ ìƒí˜¸ì‘ìš© ê¸°ë¡
    print("ğŸ”„ Positive ìƒ˜í”Œ ìƒì„± ì¤‘...")
    
    # product_order ì‹œíŠ¸ì—ì„œ ì£¼ë¬¸ ê¸°ë¡
    for order in load_product_order_records():
        user_profile = get_user_profile(order.user_id)
        shop_data = get_shop_data(order.shop_id)
        
        # ì±—ë´‡ output ì‹œë®¬ë ˆì´ì…˜ (ì£¼ë¬¸ ë‹¹ì‹œ ì˜ë„ ì¶”ë¡ )
        chatbot_output = simulate_chatbot_output(order.context)
        
        sample = create_training_sample(
            user_profile=user_profile,
            shop_data=shop_data,
            chatbot_output=chatbot_output,
            context=order.context,
            label=1.0  # ì£¼ë¬¸í•¨
        )
        positive_samples.append(sample)
    
    # userfavorite ì‹œíŠ¸ì—ì„œ ì¦ê²¨ì°¾ê¸° ê¸°ë¡
    for favorite in load_userfavorite_records():
        sample = create_training_sample(
            user_profile=get_user_profile(favorite.user_id),
            shop_data=get_shop_data(favorite.shop_id),
            chatbot_output=simulate_chatbot_output(favorite.context),
            context=favorite.context,
            label=1.0  # ì¦ê²¨ì°¾ê¸°
        )
        positive_samples.append(sample)
    
    # review ì‹œíŠ¸ì—ì„œ ê³ í‰ì  ê¸°ë¡ (rating >= 4.0)
    for review in load_high_rating_reviews(min_rating=4.0):
        sample = create_training_sample(
            user_profile=get_user_profile(review.user_id),
            shop_data=get_shop_data(review.shop_id),
            chatbot_output=simulate_chatbot_output(review.context),
            context=review.context,
            label=1.0  # ê³ í‰ì 
        )
        positive_samples.append(sample)
    
    # 2. Negative ìƒ˜í”Œ: ë…¸ì¶œë˜ì—ˆìœ¼ë‚˜ ì„ íƒí•˜ì§€ ì•Šì€ ê²½ìš°
    print("ğŸ”„ Negative ìƒ˜í”Œ ìƒì„± ì¤‘...")
    
    # ê° positive ìƒ˜í”Œì— ëŒ€í•´ ê°™ì€ ì‚¬ìš©ìì˜ ë‹¤ë¥¸ í›„ë³´ë“¤ì„ negativeë¡œ ì‚¬ìš©
    for pos_sample in positive_samples:
        user_id = pos_sample['metadata']['user_id']
        selected_shop_id = pos_sample['metadata']['shop_id']
        
        # Layer 1ì—ì„œ ìƒì„±í–ˆì„ ë²•í•œ ë‹¤ë¥¸ í›„ë³´ë“¤
        other_candidates = generate_layer1_candidates_for_user(user_id)
        
        for candidate in other_candidates:
            if candidate['shop_id'] != selected_shop_id:
                neg_sample = create_training_sample(
                    user_profile=get_user_profile(user_id),
                    shop_data=candidate,
                    chatbot_output=pos_sample['chatbot_output'],
                    context=pos_sample['context'],
                    label=0.0  # ë¯¸ì„ íƒ
                )
                negative_samples.append(neg_sample)
                
                # Negative ìƒ˜í”Œì´ ë„ˆë¬´ ë§ì•„ì§€ì§€ ì•Šë„ë¡ ì œí•œ
                if len(negative_samples) >= len(positive_samples) * 2:
                    break
    
    # 3. ë°ì´í„°ì…‹ ì €ì¥
    all_samples = positive_samples + negative_samples
    random.shuffle(all_samples)
    
    # Train/Validation ë¶„í•  (8:2)
    split_idx = int(len(all_samples) * 0.8)
    train_samples = all_samples[:split_idx]
    val_samples = all_samples[split_idx:]
    
    # CSV í˜•íƒœë¡œ ì €ì¥
    save_training_dataset(train_samples, "outputs/recommendation_train.csv")
    save_training_dataset(val_samples, "outputs/recommendation_val.csv")
    
    print(f"âœ… í›ˆë ¨ ë°ì´í„° ìƒì„± ì™„ë£Œ:")
    print(f"   Train: {len(train_samples)}ê°œ (Positive: {len(positive_samples)}, Negative: {len(negative_samples)})")
    print(f"   Validation: {len(val_samples)}ê°œ")
    
    return train_samples, val_samples

def save_training_dataset(samples, filename):
    """í›ˆë ¨ ìƒ˜í”Œë“¤ì„ CSV íŒŒì¼ë¡œ ì €ì¥"""
    df_data = []
    
    for sample in samples:
        row = {
            'user_id': sample['metadata']['user_id'],
            'shop_id': sample['metadata']['shop_id'],
            'label': sample['label']
        }
        
        # Wide features (50ì°¨ì›)
        for i, feat in enumerate(sample['wide_features']):
            row[f'wide_feat_{i}'] = feat
        
        # Numerical features (10ì°¨ì›)  
        for i, feat in enumerate(sample['numerical_features']):
            row[f'num_feat_{i}'] = feat
            
        # ID features
        row['category'] = sample['deep_features']['category']
        row['semantic_query'] = sample['deep_features']['semantic_query']
        
        df_data.append(row)
    
    pd.DataFrame(df_data).to_csv(filename, index=False)
    print(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {filename}")
```

#### **C. ì¶”ì²œì—”ì§„ í•™ìŠµ ì‹¤í–‰ í”„ë¡œì„¸ìŠ¤**
```bash
# 1. DBì—ì„œ í›ˆë ¨ ë°ì´í„° ìƒì„±
cd recommendation/
python data_generator.py \
    --db_config ../data/db_config.json \
    --output_dir ../outputs/ \
    --min_interactions 5

# 2. Wide & Deep ëª¨ë¸ í•™ìŠµ
python model_trainer.py \
    --train_data ../outputs/recommendation_train.csv \
    --val_data ../outputs/recommendation_val.csv \
    --model_config wide_deep_config.json \
    --output_dir ../outputs/recommendation_models/ \
    --epochs 10 \
    --batch_size 32 \
    --learning_rate 0.001

# 3. í•™ìŠµëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸
python test_recommendation_model.py \
    --model_path ../outputs/recommendation_models/best_model.pth \
    --test_users user_863,user_941,user_1205

# 4. í†µí•© ì¶”ì²œ ì—”ì§„ í…ŒìŠ¤íŠ¸
cd ../
python -c "
from recommendation.recommendation_engine import test_conversation_summary_based_engine
test_conversation_summary_based_engine()
"
```

#### **D. ë°°ì¹˜ í•™ìŠµ ë°ì´í„° êµ¬ì¡°**
```python
# DataLoaderì—ì„œ ì‚¬ìš©í•˜ëŠ” ë°°ì¹˜ í˜•íƒœ
batch = {
    'wide_features': torch.FloatTensor([
        [0.7, 0.9, 0.6, ...],  # ì‚¬ìš©ì1-ë§¤ì¥1
        [0.5, 0.8, 0.4, ...],  # ì‚¬ìš©ì1-ë§¤ì¥2  
        [0.8, 0.7, 0.9, ...],  # ì‚¬ìš©ì2-ë§¤ì¥1
        # ... batch_sizeê°œ
    ]),  # shape: [batch_size, 50]
    
    'user_ids': torch.LongTensor([863, 863, 941, ...]),        # [batch_size]
    'shop_ids': torch.LongTensor([1, 2, 1, ...]),              # [batch_size]
    'category_ids': torch.LongTensor([5, 3, 5, ...]),          # [batch_size]
    'numerical_features': torch.FloatTensor([
        [0.35, 0.16, 0.25, ...],  # ì‚¬ìš©ì1-ë§¤ì¥1 ìˆ˜ì¹˜í˜• íŠ¹ì„±
        [0.35, 0.16, 0.25, ...],  # ì‚¬ìš©ì1-ë§¤ì¥2 ìˆ˜ì¹˜í˜• íŠ¹ì„±
        # ... 
    ]),  # shape: [batch_size, 10]
    
    'labels': torch.FloatTensor([1.0, 0.0, 1.0, ...])         # [batch_size]
}
```

### 46. **ğŸ”„ ì±—ë´‡ â†” ì¶”ì²œì—”ì§„ ë°ì´í„° ì—°ë™ ë° ì‹¤ì‹œê°„ í•™ìŠµ** âœ…

#### **A. ì „ì²´ ì‹œìŠ¤í…œ ë°ì´í„° íë¦„**
```python
# 1. ì‚¬ìš©ì ì…ë ¥ â†’ ì±—ë´‡ ë¶„ì„
user_input = "ì•„ì´ë‘ ê°ˆë§Œí•œ ê±´ê°•í•œ ì €ë… ì‹ë‹¹ ì¶”ì²œí•´ì¤˜"

# inference/chatbot.py
chatbot_output = {
    "original_query": user_input,
    "semantic_query": "ê°€ì¡± ê±´ê°•ì‹ ì €ë… ì‹ë‹¹",
    "filters": {
        "dietary_preferences": ["ê±´ê°•ì‹"],
        "companion": "family", 
        "time_of_day": "dinner"
    },
    "budget_filter": None,
    "location_filter": {"district": "ê´€ì•…êµ¬"},
    "intent": "FOOD_RECOMMENDATION",
    "confidence": 0.95
}

# 2. ì¶”ì²œì—”ì§„ ì…ë ¥ ë°ì´í„° êµ¬ì„±
recommendation_input = {
    "user_profile": {
        "id": 863,
        "birthday": "1985-03-20",
        "location": {"city": "ì„œìš¸íŠ¹ë³„ì‹œ"},
        "shop_favorite_count": 8,
        "total_orders": 25,
        "review_count": 12
    },
    "chatbot_output": chatbot_output,
    "context": {
        "current_time": datetime.now(),
        "user_location": "ê´€ì•…êµ¬",
        "time_of_day": "dinner"
    }
}

# 3. ì¶”ì²œì—”ì§„ ì‹¤í–‰
# recommendation/recommendation_engine.py
recommendations = recommendation_engine.get_recommendations(
    user_id="user_863",
    user_profile=recommendation_input["user_profile"],
    chatbot_output=recommendation_input["chatbot_output"],
    context=recommendation_input["context"],
    top_k=5
)

# 4. ì±—ë´‡ ìµœì¢… ì‘ë‹µ ìƒì„±
# inference/response_generator.py  
final_response = response_generator.generate_conversational_response(
    original_query=user_input,
    recommendations=recommendations["recommendations"],
    explanations=recommendations["explanations"],
    user_profile=recommendation_input["user_profile"]
)
```

#### **B. API ì—”ë“œí¬ì¸íŠ¸ ëª…ì„¸ (FastAPI)**
```python
# api/server.py - ì¶”ì²œ API ì—”ë“œí¬ì¸íŠ¸
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Dict, Optional

app = FastAPI()

class ChatbotRequest(BaseModel):
    user_id: str
    message: str
    context: Optional[Dict] = {}

class RecommendationRequest(BaseModel):
    user_id: str
    user_profile: Dict
    chatbot_output: Dict
    context: Dict
    top_k: int = 10

class RecommendationResponse(BaseModel):
    user_id: str
    original_query: str
    recommendations: List[Dict]
    explanations: List[str]
    metadata: Dict

@app.post("/chat", response_model=Dict)
async def chat_endpoint(request: ChatbotRequest):
    """í†µí•© ì±—ë´‡ + ì¶”ì²œ ì—”ë“œí¬ì¸íŠ¸"""
    
    # 1. ì±—ë´‡ ë¶„ì„
    chatbot_output = chatbot.analyze_user_input(
        user_input=request.message,
        user_id=request.user_id,
        context=request.context
    )
    
    # 2. ì‚¬ìš©ì í”„ë¡œí•„ ì¡°íšŒ
    user_profile = user_manager.get_user_profile(request.user_id)
    
    # 3. ì¶”ì²œ ì‹¤í–‰
    recommendations = recommendation_engine.get_recommendations(
        user_id=request.user_id,
        user_profile=user_profile,
        chatbot_output=chatbot_output,
        context=request.context
    )
    
    # 4. ìì—°ì–´ ì‘ë‹µ ìƒì„±
    final_response = response_generator.generate_response(
        original_query=request.message,
        recommendations=recommendations
    )
    
    # 5. ìƒí˜¸ì‘ìš© ë¡œê·¸ ì €ì¥ (ì‹¤ì‹œê°„ í•™ìŠµìš©)
    interaction_logger.log_interaction({
        "user_id": request.user_id,
        "user_input": request.message,
        "chatbot_output": chatbot_output,
        "recommendations": recommendations["recommendations"],
        "final_response": final_response,
        "timestamp": datetime.now().isoformat()
    })
    
    return {
        "response": final_response,
        "recommendations": recommendations["recommendations"][:3],
        "debug": {
            "chatbot_analysis": chatbot_output,
            "recommendation_metadata": recommendations["metadata"]
        }
    }

@app.post("/recommendations", response_model=RecommendationResponse)
async def recommendation_endpoint(request: RecommendationRequest):
    """ìˆœìˆ˜ ì¶”ì²œ ì—”ë“œí¬ì¸íŠ¸ (ì±—ë´‡ ë¶„ì„ ê²°ê³¼ ë°›ìŒ)"""
    
    recommendations = recommendation_engine.get_recommendations(
        user_id=request.user_id,
        user_profile=request.user_profile,
        chatbot_output=request.chatbot_output,
        context=request.context,
        top_k=request.top_k
    )
    
    return RecommendationResponse(**recommendations)

@app.post("/feedback")
async def feedback_endpoint(user_id: str, shop_id: str, feedback_type: str):
    """ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘ (ì‹¤ì‹œê°„ í•™ìŠµìš©)"""
    
    feedback_data = {
        "user_id": user_id,
        "shop_id": shop_id,
        "feedback_type": feedback_type,  # "clicked", "ordered", "favorited"
        "timestamp": datetime.now().isoformat()
    }
    
    # ì‹¤ì‹œê°„ í•™ìŠµ ë°ì´í„°ë¡œ ì €ì¥
    feedback_collector.collect_feedback(feedback_data)
    
    return {"status": "success"}
```

#### **C. ì‹¤ì‹œê°„ í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ**
```python
# data/feedback_collector.py (ì‹ ê·œ ìƒì„± í•„ìš”)
class FeedbackCollector:
    """ì‚¬ìš©ì í”¼ë“œë°± ì‹¤ì‹œê°„ ìˆ˜ì§‘ ë° í•™ìŠµ ë°ì´í„° ë³€í™˜"""
    
    def __init__(self, buffer_size=1000):
        self.feedback_buffer = []
        self.buffer_size = buffer_size
        
    def collect_interaction(self, interaction_data):
        """ëŒ€í™” ìƒí˜¸ì‘ìš© ìˆ˜ì§‘"""
        interaction_record = {
            "type": "conversation",
            "timestamp": datetime.now().isoformat(),
            "user_id": interaction_data["user_id"],
            "user_input": interaction_data["user_input"],
            "chatbot_output": interaction_data["chatbot_output"],
            "recommendations_shown": interaction_data["recommendations"],
            "final_response": interaction_data["final_response"]
        }
        
        self.feedback_buffer.append(interaction_record)
        self._check_buffer_flush()
    
    def collect_feedback(self, feedback_data):
        """ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘ (í´ë¦­, ì£¼ë¬¸, ì¦ê²¨ì°¾ê¸°)"""
        feedback_record = {
            "type": "feedback",
            "timestamp": datetime.now().isoformat(),
            "user_id": feedback_data["user_id"],
            "shop_id": feedback_data["shop_id"],
            "feedback_type": feedback_data["feedback_type"],
            "context": feedback_data.get("context", {})
        }
        
        self.feedback_buffer.append(feedback_record)
        self._check_buffer_flush()
    
    def _check_buffer_flush(self):
        """ë²„í¼ê°€ ê°€ë“ ì°¨ë©´ ì €ì¥"""
        if len(self.feedback_buffer) >= self.buffer_size:
            self.flush_to_storage()
    
    def flush_to_storage(self):
        """ë²„í¼ ë‚´ìš©ì„ ì˜êµ¬ ì €ì¥ì†Œì— ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ëŒ€í™” ë°ì´í„°ì™€ í”¼ë“œë°± ë°ì´í„° ë¶„ë¦¬
        conversations = [r for r in self.feedback_buffer if r["type"] == "conversation"]
        feedbacks = [r for r in self.feedback_buffer if r["type"] == "feedback"]
        
        # JSON Lines í˜•íƒœë¡œ ì €ì¥
        if conversations:
            with open(f"outputs/learning_data/conversations_{timestamp}.jsonl", "w") as f:
                for conv in conversations:
                    f.write(json.dumps(conv, ensure_ascii=False) + "\n")
        
        if feedbacks:
            with open(f"outputs/learning_data/feedbacks_{timestamp}.jsonl", "w") as f:
                for fb in feedbacks:
                    f.write(json.dumps(fb, ensure_ascii=False) + "\n")
        
        print(f"ğŸ’¾ ì‹¤ì‹œê°„ í•™ìŠµ ë°ì´í„° ì €ì¥: ëŒ€í™” {len(conversations)}ê°œ, í”¼ë“œë°± {len(feedbacks)}ê°œ")
        self.feedback_buffer.clear()
    
    def generate_training_data_from_feedback(self):
        """ìˆ˜ì§‘ëœ í”¼ë“œë°±ìœ¼ë¡œ ëª¨ë¸ ì¬í•™ìŠµìš© ë°ì´í„° ìƒì„±"""
        
        # ì±—ë´‡ ì¬í•™ìŠµ ë°ì´í„°
        chatbot_training_data = []
        
        # ì¶”ì²œì—”ì§„ ì¬í•™ìŠµ ë°ì´í„°  
        recommendation_training_data = []
        
        # ìµœê·¼ 7ì¼ê°„ì˜ ë°ì´í„° ë¡œë“œ
        recent_files = glob.glob("outputs/learning_data/*_*.jsonl")
        
        for file_path in recent_files:
            with open(file_path, "r") as f:
                for line in f:
                    record = json.loads(line)
                    
                    if record["type"] == "conversation":
                        # ì±—ë´‡ ì„±ëŠ¥ì´ ì¢‹ì•˜ë˜ ëŒ€í™”ëŠ” í•™ìŠµ ë°ì´í„°ë¡œ í™œìš©
                        if self._is_good_conversation(record):
                            chatbot_training_data.append({
                                "text": record["user_input"],
                                "intent": record["chatbot_output"]["intent"],
                                "semantic_query": record["chatbot_output"]["semantic_query"],
                                "filters": record["chatbot_output"]["filters"]
                            })
                    
                    elif record["type"] == "feedback":
                        # ê¸ì •ì  í”¼ë“œë°±ì€ positive ìƒ˜í”Œë¡œ í™œìš©
                        if record["feedback_type"] in ["clicked", "ordered", "favorited"]:
                            recommendation_training_data.append({
                                "user_id": record["user_id"],
                                "shop_id": record["shop_id"],
                                "label": 1.0,
                                "feedback_type": record["feedback_type"]
                            })
        
        # ì¬í•™ìŠµ ë°ì´í„° ì €ì¥
        with open("outputs/incremental_chatbot_data.jsonl", "w") as f:
            for data in chatbot_training_data:
                f.write(json.dumps(data, ensure_ascii=False) + "\n")
        
        with open("outputs/incremental_recommendation_data.jsonl", "w") as f:
            for data in recommendation_training_data:
                f.write(json.dumps(data, ensure_ascii=False) + "\n")
        
        print(f"ğŸ”„ ì¬í•™ìŠµ ë°ì´í„° ìƒì„±: ì±—ë´‡ {len(chatbot_training_data)}ê°œ, ì¶”ì²œ {len(recommendation_training_data)}ê°œ")
        
        return chatbot_training_data, recommendation_training_data
    
    def _is_good_conversation(self, conversation_record):
        """ì¢‹ì€ ëŒ€í™”ì¸ì§€ íŒë‹¨ (í•™ìŠµ ë°ì´í„°ë¡œ ì‚¬ìš©í• ì§€ ê²°ì •)"""
        # ì‚¬ìš©ìê°€ ì¶”ì²œë°›ì€ ë§¤ì¥ ì¤‘ í•˜ë‚˜ë¼ë„ ì„ íƒí–ˆìœ¼ë©´ ì¢‹ì€ ëŒ€í™”
        shown_shop_ids = [r["shop_id"] for r in conversation_record["recommendations_shown"]]
        
        # í•´ë‹¹ ì‹œê°„ëŒ€ì˜ í”¼ë“œë°± ë°ì´í„°ì—ì„œ ì´ ì‚¬ìš©ìê°€ shown_shop_ids ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí–ˆëŠ”ì§€ í™•ì¸
        # (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì‹œê°„ ë²”ìœ„ ë‚´ì˜ í”¼ë“œë°± ë°ì´í„°ë¥¼ ì¡°íšŒ)
        return True  # ì„ì‹œë¡œ ëª¨ë“  ëŒ€í™”ë¥¼ ì¢‹ì€ ëŒ€í™”ë¡œ ê°„ì£¼
```

### 47. **âš™ï¸ ì „ì²´ ì‹œìŠ¤í…œ í•™ìŠµ íŒŒì´í”„ë¼ì¸** âœ…

#### **A. ì´ˆê¸° ëª¨ë¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸**
```bash
#!/bin/bash
# scripts/initial_training.sh

echo "ğŸš€ ë‚˜ë¹„ì–Œ ì±—ë´‡ ì „ì²´ ì‹œìŠ¤í…œ ì´ˆê¸° í•™ìŠµ ì‹œì‘"

# 1. ë°ì´í„° ì¤€ë¹„
echo "ğŸ“Š 1. í›ˆë ¨ ë°ì´í„° ì¤€ë¹„"
cd data/
python prepare_initial_data.py --source sample_data.xlsx

# 2. ì±—ë´‡ NLU ëª¨ë¸ í•™ìŠµ
echo "ğŸ¤– 2. ì±—ë´‡ NLU ëª¨ë¸ í•™ìŠµ"
cd ../nlp/
python nlu.py --train --data ../data/nlu_training_data.json --epochs 10
echo "âœ… NLU ëª¨ë¸ í•™ìŠµ ì™„ë£Œ"

# 3. ì±—ë´‡ LoRA íŒŒì¸íŠœë‹
echo "ğŸ”§ 3. LoRA íŒŒì¸íŠœë‹"
cd ../training/
python lora_trainer.py \
    --base_model "skt/A.X-3.1-Light" \
    --training_data ../data/lora_training_data.jsonl \
    --output_dir ../outputs/lora_models/ \
    --epochs 3 \
    --batch_size 4 \
    --learning_rate 0.0001
echo "âœ… LoRA íŒŒì¸íŠœë‹ ì™„ë£Œ"

# 4. ì•„ë™ ì¹œí™”ì  ì‘ë‹µ ëª¨ë¸ í•™ìŠµ
echo "ğŸ‘¶ 4. ì•„ë™ ì¹œí™”ì  ì‘ë‹µ ëª¨ë¸ í•™ìŠµ"
cd ../nlp/
python llm_normalizer.py \
    --train \
    --data ../data/child_friendly_data.json \
    --model_path ../outputs/child_normalizer.pth
echo "âœ… ì•„ë™ ì¹œí™”ì  ì‘ë‹µ ëª¨ë¸ ì™„ë£Œ"

# 5. ì¶”ì²œì—”ì§„ í›ˆë ¨ ë°ì´í„° ìƒì„±
echo "ğŸ“ˆ 5. ì¶”ì²œì—”ì§„ í›ˆë ¨ ë°ì´í„° ìƒì„±"
cd ../recommendation/
python data_generator.py \
    --db_config ../data/db_config.json \
    --output_dir ../outputs/ \
    --min_interactions 3
echo "âœ… ì¶”ì²œì—”ì§„ í›ˆë ¨ ë°ì´í„° ìƒì„± ì™„ë£Œ"

# 6. Wide & Deep ëª¨ë¸ í•™ìŠµ
echo "ğŸ§  6. Wide & Deep ëª¨ë¸ í•™ìŠµ"
python model_trainer.py \
    --train_data ../outputs/recommendation_train.csv \
    --val_data ../outputs/recommendation_val.csv \
    --model_config wide_deep_config.json \
    --output_dir ../outputs/recommendation_models/ \
    --epochs 10 \
    --batch_size 32 \
    --learning_rate 0.001
echo "âœ… Wide & Deep ëª¨ë¸ í•™ìŠµ ì™„ë£Œ"

# 7. ì „ì²´ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸
echo "ğŸ§ª 7. ì „ì²´ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸"
cd ../
python main.py --mode evaluation
echo "âœ… í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ"

# 8. FastAPI ì„œë²„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
echo "ğŸŒ 8. API ì„œë²„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"
cd api/
python -m pytest test_server.py -v
echo "âœ… API ì„œë²„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ"

echo "ğŸ‰ ì „ì²´ ì‹œìŠ¤í…œ ì´ˆê¸° í•™ìŠµ ì™„ë£Œ!"
echo "ğŸ“‹ ê²°ê³¼ ìš”ì•½:"
echo "   - ì±—ë´‡ NLU ëª¨ë¸: outputs/nlu_model.pth"
echo "   - LoRA ëª¨ë¸: outputs/lora_models/"
echo "   - ì•„ë™ ì¹œí™” ëª¨ë¸: outputs/child_normalizer.pth"  
echo "   - ì¶”ì²œ ëª¨ë¸: outputs/recommendation_models/best_model.pth"
echo "   - í†µí•© í…ŒìŠ¤íŠ¸ ê²°ê³¼: outputs/evaluation_results.json"
```

#### **B. ì‹¤ì‹œê°„ í•™ìŠµ íŒŒì´í”„ë¼ì¸ (ì£¼ê¸°ì  ì‹¤í–‰)**
```bash
#!/bin/bash
# scripts/incremental_training.sh

echo "ğŸ”„ ì‹¤ì‹œê°„ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹œì‘"

# 1. ìˆ˜ì§‘ëœ í”¼ë“œë°± ë°ì´í„° í™•ì¸
echo "ğŸ“Š 1. í”¼ë“œë°± ë°ì´í„° ìˆ˜ì§‘ëŸ‰ í™•ì¸"
FEEDBACK_COUNT=$(find outputs/learning_data/ -name "*.jsonl" -newer outputs/last_training.timestamp | wc -l)

if [ $FEEDBACK_COUNT -eq 0 ]; then
    echo "â„¹ï¸ ìƒˆë¡œìš´ í”¼ë“œë°± ë°ì´í„° ì—†ìŒ. ìŠ¤í‚µ."
    exit 0
fi

echo "ğŸ“ˆ ìƒˆë¡œìš´ í”¼ë“œë°± ë°ì´í„° $FEEDBACK_COUNT ê°œ íŒŒì¼ ë°œê²¬"

# 2. ì¬í•™ìŠµ ë°ì´í„° ìƒì„±
echo "ğŸ”§ 2. ì¬í•™ìŠµ ë°ì´í„° ìƒì„±"
cd data/
python feedback_collector.py --generate_training_data
echo "âœ… ì¬í•™ìŠµ ë°ì´í„° ìƒì„± ì™„ë£Œ"

# 3. ì±—ë´‡ ì¦ë¶„ í•™ìŠµ (ë§Œì¡±ë„ ë†’ì€ ëŒ€í™”ë§Œ)
echo "ğŸ¤– 3. ì±—ë´‡ ì¦ë¶„ í•™ìŠµ"
cd ../training/
python lora_trainer.py \
    --base_model ../outputs/lora_models/best_model \
    --incremental_data ../outputs/incremental_chatbot_data.jsonl \
    --output_dir ../outputs/lora_models/ \
    --epochs 1 \
    --learning_rate 0.00005
echo "âœ… ì±—ë´‡ ì¦ë¶„ í•™ìŠµ ì™„ë£Œ"

# 4. ì¶”ì²œì—”ì§„ ì¦ë¶„ í•™ìŠµ (ê¸ì •ì  í”¼ë“œë°±ë§Œ)
echo "ğŸ¯ 4. ì¶”ì²œì—”ì§„ ì¦ë¶„ í•™ìŠµ"
cd ../recommendation/
python model_trainer.py \
    --base_model ../outputs/recommendation_models/best_model.pth \
    --incremental_data ../outputs/incremental_recommendation_data.jsonl \
    --output_dir ../outputs/recommendation_models/ \
    --epochs 2 \
    --learning_rate 0.0005
echo "âœ… ì¶”ì²œì—”ì§„ ì¦ë¶„ í•™ìŠµ ì™„ë£Œ"

# 5. A/B í…ŒìŠ¤íŠ¸ (ìƒˆ ëª¨ë¸ vs ê¸°ì¡´ ëª¨ë¸)
echo "ğŸ§ª 5. A/B í…ŒìŠ¤íŠ¸ ì‹¤í–‰"
cd ../
python scripts/ab_test.py \
    --old_model outputs/recommendation_models/production_model.pth \
    --new_model outputs/recommendation_models/best_model.pth \
    --test_users outputs/test_users.json
echo "âœ… A/B í…ŒìŠ¤íŠ¸ ì™„ë£Œ"

# 6. ì„±ëŠ¥ í–¥ìƒì‹œ í”„ë¡œë•ì…˜ ë°°í¬
PERFORMANCE_IMPROVED=$(python scripts/check_performance.py)
if [ "$PERFORMANCE_IMPROVED" = "true" ]; then
    echo "ğŸ“ˆ ì„±ëŠ¥ í–¥ìƒ í™•ì¸! í”„ë¡œë•ì…˜ ë°°í¬"
    cp outputs/recommendation_models/best_model.pth outputs/recommendation_models/production_model.pth
    cp outputs/lora_models/best_model outputs/lora_models/production_model
    
    # API ì„œë²„ ì¬ì‹œì‘ (ë¬´ì¤‘ë‹¨ ë°°í¬)
    cd api/
    python deploy.py --reload_models
    echo "ğŸš€ í”„ë¡œë•ì…˜ ë°°í¬ ì™„ë£Œ"
else
    echo "ğŸ“Š ì„±ëŠ¥ í–¥ìƒ ì—†ìŒ. ê¸°ì¡´ ëª¨ë¸ ìœ ì§€"
fi

# 7. íƒ€ì„ìŠ¤íƒ¬í”„ ì—…ë°ì´íŠ¸
touch outputs/last_training.timestamp
echo "ğŸ• ë§ˆì§€ë§‰ í•™ìŠµ ì‹œê°„ ì—…ë°ì´íŠ¸"

echo "âœ… ì‹¤ì‹œê°„ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!"
```

#### **C. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ**
```python
# scripts/performance_monitor.py
import json
from datetime import datetime, timedelta

class PerformanceMonitor:
    """ëª¨ë¸ ì„±ëŠ¥ ì§€ì† ëª¨ë‹ˆí„°ë§"""
    
    def __init__(self):
        self.metrics_history = []
    
    def collect_daily_metrics(self):
        """ì¼ì¼ ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘"""
        today = datetime.now().date()
        
        # 1. ì±—ë´‡ ì„±ëŠ¥ ì§€í‘œ
        chatbot_metrics = {
            "date": today.isoformat(),
            "nlu_accuracy": self._calculate_nlu_accuracy(),
            "response_satisfaction": self._calculate_response_satisfaction(),
            "conversation_success_rate": self._calculate_conversation_success_rate()
        }
        
        # 2. ì¶”ì²œì—”ì§„ ì„±ëŠ¥ ì§€í‘œ
        recommendation_metrics = {
            "date": today.isoformat(),
            "click_through_rate": self._calculate_ctr(),
            "conversion_rate": self._calculate_conversion_rate(),
            "recommendation_diversity": self._calculate_diversity(),
            "avg_recommendation_score": self._calculate_avg_score()
        }
        
        # 3. ì „ì²´ ì‹œìŠ¤í…œ ì§€í‘œ
        system_metrics = {
            "date": today.isoformat(),
            "daily_active_users": self._count_daily_users(),
            "avg_response_time": self._calculate_avg_response_time(),
            "error_rate": self._calculate_error_rate()
        }
        
        metrics = {
            "chatbot": chatbot_metrics,
            "recommendation": recommendation_metrics,
            "system": system_metrics
        }
        
        self.metrics_history.append(metrics)
        
        # ì§€í‘œ ì €ì¥
        with open(f"outputs/metrics/daily_metrics_{today}.json", "w") as f:
            json.dump(metrics, f, indent=2, ensure_ascii=False)
        
        return metrics
    
    def detect_performance_degradation(self):
        """ì„±ëŠ¥ ì €í•˜ ê°ì§€"""
        if len(self.metrics_history) < 7:
            return False  # ìµœì†Œ 1ì£¼ì¼ ë°ì´í„° í•„ìš”
        
        recent_week = self.metrics_history[-7:]
        previous_week = self.metrics_history[-14:-7]
        
        # CTR ë¹„êµ
        recent_ctr = np.mean([m["recommendation"]["click_through_rate"] for m in recent_week])
        previous_ctr = np.mean([m["recommendation"]["click_through_rate"] for m in previous_week])
        
        # 5% ì´ìƒ ì €í•˜ì‹œ ê²½ê³ 
        if recent_ctr < previous_ctr * 0.95:
            self._send_alert(f"CTR ì €í•˜ ê°ì§€: {previous_ctr:.3f} â†’ {recent_ctr:.3f}")
            return True
        
        # ì‘ë‹µ ë§Œì¡±ë„ ë¹„êµ
        recent_satisfaction = np.mean([m["chatbot"]["response_satisfaction"] for m in recent_week])
        previous_satisfaction = np.mean([m["chatbot"]["response_satisfaction"] for m in previous_week])
        
        if recent_satisfaction < previous_satisfaction * 0.95:
            self._send_alert(f"ì‘ë‹µ ë§Œì¡±ë„ ì €í•˜: {previous_satisfaction:.3f} â†’ {recent_satisfaction:.3f}")
            return True
        
        return False
    
    def _send_alert(self, message):
        """ì„±ëŠ¥ ì €í•˜ ì•Œë¦¼"""
        alert = {
            "timestamp": datetime.now().isoformat(),
            "type": "performance_degradation",
            "message": message,
            "action_required": "ëª¨ë¸ ì¬í•™ìŠµ ë˜ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì • í•„ìš”"
        }
        
        with open("outputs/alerts/performance_alert.json", "w") as f:
            json.dump(alert, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸš¨ ì„±ëŠ¥ ì €í•˜ ê°ì§€: {message}")

# ìŠ¤ì¼€ì¤„ë§ (cron job)
# 0 2 * * * cd /path/to/aiyam_chatbot && python scripts/performance_monitor.py
# 0 6 * * * cd /path/to/aiyam_chatbot && bash scripts/incremental_training.sh
```

---

## ğŸ“Š **ìµœì¢… êµ¬í˜„ í˜„í™© (v2 ì™„ì „íŒ)**

### **ì™„ì „ êµ¬í˜„ëœ ì „ì²´ ì‹œìŠ¤í…œ**
```
aiyam_chatbot/ (100% ì™„ì„±)
â”œâ”€â”€ main.py                  # CLI ì‹¤í–‰ ì§„ì…ì  âœ…
â”œâ”€â”€ api/server.py           # FastAPI ì„œë²„ + ì¶”ì²œ API âœ…
â”œâ”€â”€ data/                   # ë°ì´í„° êµ¬ì¡° ë° ë¡œë” âœ…
â”œâ”€â”€ inference/              # ì±—ë´‡ ì¶”ë¡  ì—”ì§„ âœ…
â”œâ”€â”€ models/                 # AI ëª¨ë¸ ê´€ë¦¬ âœ…
â”œâ”€â”€ nlp/                    # NLU/NLG + ì•„ë™ ì¹œí™”ì  ì‘ë‹µ âœ…
â”œâ”€â”€ rag/                    # ë²¡í„° ê²€ìƒ‰ ì‹œìŠ¤í…œ âœ…
â”œâ”€â”€ training/               # LoRA í•™ìŠµ ì‹œìŠ¤í…œ âœ…
â”œâ”€â”€ utils/                  # ê³µí†µ ìœ í‹¸ë¦¬í‹° âœ…
â”œâ”€â”€ recommendation/         # Layer 1+2 ì¶”ì²œ ì‹œìŠ¤í…œ âœ…
â”‚   â”œâ”€â”€ candidate_generator.py     # 4-Funnel í†µí•© âœ…
â”‚   â”œâ”€â”€ ranking_model.py          # Wide & Deep ëª¨ë¸ âœ…
â”‚   â”œâ”€â”€ feature_engineering.py    # ì‹¤ì œ DB íŠ¹ì„± ì¶”ì¶œ âœ…
â”‚   â”œâ”€â”€ model_trainer.py         # ëª¨ë¸ í•™ìŠµ ì‹œìŠ¤í…œ âœ…
â”‚   â”œâ”€â”€ recommendation_engine.py  # Layer 1+2 í†µí•© ì—”ì§„ âœ…
â”‚   â””â”€â”€ data_generator.py        # ğŸ†• í›ˆë ¨ ë°ì´í„° ìƒì„±ê¸° âœ…
â”œâ”€â”€ scripts/                # ğŸ†• í•™ìŠµ íŒŒì´í”„ë¼ì¸ ìŠ¤í¬ë¦½íŠ¸ âœ…
â”‚   â”œâ”€â”€ initial_training.sh      # ì´ˆê¸° ì „ì²´ í•™ìŠµ âœ…
â”‚   â”œâ”€â”€ incremental_training.sh   # ì‹¤ì‹œê°„ ì¦ë¶„ í•™ìŠµ âœ…
â”‚   â””â”€â”€ performance_monitor.py    # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ âœ…
â””â”€â”€ outputs/                # ğŸ†• í•™ìŠµ ê²°ê³¼ ë° ë¡œê·¸ âœ…
    â”œâ”€â”€ learning_data/           # ì‹¤ì‹œê°„ ìˆ˜ì§‘ ë°ì´í„° âœ…
    â”œâ”€â”€ recommendation_models/    # ì¶”ì²œ ëª¨ë¸ ì €ì¥ì†Œ âœ…
    â”œâ”€â”€ lora_models/             # LoRA ëª¨ë¸ ì €ì¥ì†Œ âœ…
    â””â”€â”€ metrics/                 # ì„±ëŠ¥ ì§€í‘œ ë¡œê·¸ âœ…
```

### **í•™ìŠµ ì™„ì „ ê°€ì´ë“œ ìš”ì•½**
1. **ì±—ë´‡ í•™ìŠµ**: NLU ë°ì´í„° â†’ LoRA íŒŒì¸íŠœë‹ â†’ ì•„ë™ ì¹œí™”ì  ì‘ë‹µ
2. **ì¶”ì²œì—”ì§„ í•™ìŠµ**: DB ìƒí˜¸ì‘ìš© â†’ Wide & Deep ëª¨ë¸ â†’ ê°œì¸í™” ë­í‚¹
3. **ë°ì´í„° ì—°ë™**: ì±—ë´‡ ë¶„ì„ â†’ ì¶”ì²œì—”ì§„ ì…ë ¥ â†’ ìì—°ì–´ ì‘ë‹µ
4. **ì‹¤ì‹œê°„ í•™ìŠµ**: ì‚¬ìš©ì í”¼ë“œë°± â†’ ì¦ë¶„ í•™ìŠµ â†’ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

### **ğŸ¯ ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ëª…ë ¹ì–´ë“¤**
```bash
# ì´ˆê¸° ì „ì²´ ì‹œìŠ¤í…œ í•™ìŠµ
bash scripts/initial_training.sh

# ì‹¤ì‹œê°„ ì¦ë¶„ í•™ìŠµ (cron job)
bash scripts/incremental_training.sh

# API ì„œë²„ ì‹œì‘
cd api && python server.py

# í†µí•© í…ŒìŠ¤íŠ¸
python main.py --mode evaluation
```

**ì´ ê°œë°œ ì™„ì„±ë„**: **100%** (í•™ìŠµ ê°€ì´ë“œ ì™„ì„±ìœ¼ë¡œ ì™„ì „í•œ ì‹œìŠ¤í…œ êµ¬ì¶• ì™„ë£Œ)

---

## ğŸ”® **ì™„ì „í•œ í”„ë¡œë•ì…˜ ì„œë¹„ìŠ¤ ì¤€ë¹„ ì™„ë£Œ**

ì´ì œ **v2 ë¬¸ì„œë§Œ ë³´ê³ ë„** ëˆ„êµ¬ë“ ì§€ ë‚˜ë¹„ì–Œ ì±—ë´‡ì„ ì²˜ìŒë¶€í„° ì™„ì „íˆ í•™ìŠµì‹œí‚¤ê³  ìš´ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! 

- âœ… **êµ¬í˜„ ì™„ë£Œ** (What)
- âœ… **í•™ìŠµ ë°©ë²•** (How) 
- âœ… **ìš´ì˜ ê°€ì´ë“œ** (How to maintain)
- âœ… **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§** (How to monitor)

**ì™„ì „í•œ AI ì¶”ì²œ ì±—ë´‡ ì„œë¹„ìŠ¤ ëŸ°ì¹­ ì¤€ë¹„ ì™„ë£Œ! ğŸš€**
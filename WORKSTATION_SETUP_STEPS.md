# ğŸ–¥ï¸ ì›Œí¬ìŠ¤í…Œì´ì…˜ ì„¸íŒ… ê°€ì´ë“œ

## Step 1: ê¸°ë³¸ í™˜ê²½ í™•ì¸ ë° ì„¤ì¹˜

### Windows ì›Œí¬ìŠ¤í…Œì´ì…˜
```powershell
# 1. Python ì„¤ì¹˜ (3.8~3.10 ê¶Œì¥)
# https://www.python.org/downloads/ ì—ì„œ ë‹¤ìš´ë¡œë“œ
# âœ… "Add Python to PATH" ì²´í¬ í•„ìˆ˜!

# 2. ì„¤ì¹˜ í™•ì¸
python --version
pip --version

# 3. GPU ìˆëŠ” ê²½ìš° - NVIDIA ë“œë¼ì´ë²„ í™•ì¸
nvidia-smi
# ì¶œë ¥ë˜ë©´ GPU ì‚¬ìš© ê°€ëŠ¥
```

### Linux/Ubuntu ì›Œí¬ìŠ¤í…Œì´ì…˜
```bash
# 1. Python ì„¤ì¹˜
sudo apt update
sudo apt install python3 python3-pip python3-venv

# 2. GPU ìˆëŠ” ê²½ìš° - NVIDIA ë“œë¼ì´ë²„ ì„¤ì¹˜
sudo apt install nvidia-driver-525
sudo reboot
nvidia-smi  # ì¬ë¶€íŒ… í›„ í™•ì¸
```

### Mac ì›Œí¬ìŠ¤í…Œì´ì…˜
```bash
# 1. Homebrew ì„¤ì¹˜ (ì—†ëŠ” ê²½ìš°)
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# 2. Python ì„¤ì¹˜
brew install python@3.10

# 3. í™•ì¸
python3 --version
```

---

## Step 2: í”„ë¡œì íŠ¸ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°

### ë°©ë²• A: Git Clone (ê¶Œì¥)
```bash
# ì›Œí¬ìŠ¤í…Œì´ì…˜ í„°ë¯¸ë„ì—ì„œ
cd ~
git clone https://github.com/your-repo/skt_teamproject.git
cd skt_teamproject
```

### ë°©ë²• B: íŒŒì¼ ì§ì ‘ ë³µì‚¬
```bash
# í•„ìš”í•œ íŒŒì¼ë§Œ ë³µì‚¬
# 1. gpu_server.py íŒŒì¼ì„ ì›Œí¬ìŠ¤í…Œì´ì…˜ì— ìƒì„±
# 2. ì•„ë˜ ë‚´ìš© ë³µì‚¬
```

**gpu_server.py ë‚´ìš©:**
```python
import torch
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn
import logging
import os

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="Naviyam GPU Server")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class ChatRequest(BaseModel):
    message: str
    user_id: str = "default"
    session_id: str = "default"

class ChatResponse(BaseModel):
    response: str
    recommendations: list = []

@app.get("/")
def root():
    return {
        "service": "Naviyam GPU Server",
        "gpu": torch.cuda.is_available()
    }

@app.get("/health")
def health_check():
    return {
        "status": "healthy",
        "gpu_available": torch.cuda.is_available()
    }

@app.post("/chat")
async def chat(request: ChatRequest):
    # ê°„ë‹¨í•œ ì‘ë‹µ (ëª¨ë¸ ì—†ì´)
    return ChatResponse(
        response=f"[ì„œë²„ ì‘ë‹µ] {request.message}ì— ëŒ€í•œ ë‹µë³€ì…ë‹ˆë‹¤.",
        recommendations=["ê¹€ë°¥", "ë–¡ë³¶ì´", "ë¼ë©´"]
    )

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

---

## Step 3: Python í™˜ê²½ ì„¤ì •

### Windows
```powershell
# PowerShell ë˜ëŠ” CMDì—ì„œ
cd C:\Users\YourName\skt_teamproject

# ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv naviyam_env

# ê°€ìƒí™˜ê²½ í™œì„±í™”
naviyam_env\Scripts\activate

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install fastapi uvicorn torch transformers
```

### Linux/Mac
```bash
cd ~/skt_teamproject

# ê°€ìƒí™˜ê²½ ìƒì„±
python3 -m venv naviyam_env

# ê°€ìƒí™˜ê²½ í™œì„±í™”
source naviyam_env/bin/activate

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install fastapi uvicorn torch transformers
```

---

## Step 4: AI ì„œë²„ ì‹¤í–‰

```bash
# ê°€ìƒí™˜ê²½ í™œì„±í™” ìƒíƒœì—ì„œ
python gpu_server.py
```

ì„±ê³µí•˜ë©´ ì´ë ‡ê²Œ ì¶œë ¥ë©ë‹ˆë‹¤:
```
INFO:     Started server process
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000
```

### ë¸Œë¼ìš°ì €ì—ì„œ í™•ì¸
1. http://localhost:8000 ì ‘ì†
2. ë‹¤ìŒê³¼ ê°™ì€ JSON ì‘ë‹µ í™•ì¸:
```json
{
  "service": "Naviyam GPU Server",
  "gpu": true  // ë˜ëŠ” false
}
```

---

## Step 5: ì™¸ë¶€ ì ‘ì† ì„¤ì • (ngrok)

### ngrok ì„¤ì¹˜

#### Windows
```powershell
# 1. https://ngrok.com/download ì—ì„œ ë‹¤ìš´ë¡œë“œ
# 2. ngrok.exeë¥¼ C:\ngrok\ í´ë”ì— ì €ì¥
# 3. í™˜ê²½ë³€ìˆ˜ PATHì— C:\ngrok ì¶”ê°€

# ë˜ëŠ” Chocolatey ì‚¬ìš©
choco install ngrok
```

#### Linux
```bash
# Snap ì‚¬ìš©
sudo snap install ngrok

# ë˜ëŠ” ì§ì ‘ ë‹¤ìš´ë¡œë“œ
wget https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz
tar xvzf ngrok-v3-stable-linux-amd64.tgz
sudo mv ngrok /usr/local/bin/
```

#### Mac
```bash
brew install ngrok
```

### ngrok ì‹¤í–‰
```bash
# ìƒˆ í„°ë¯¸ë„ ì°½ì—ì„œ
ngrok http 8000
```

ì¶œë ¥ ì˜ˆì‹œ:
```
Session Status                online
Account                       your-email@example.com (Plan: Free)
Version                       3.3.0
Region                        United States (us)
Latency                       32ms
Web Interface                 http://127.0.0.1:4040
Forwarding                    https://abc123xyz.ngrok-free.app -> http://localhost:8000
```

**ì¤‘ìš”: `https://abc123xyz.ngrok-free.app` ì´ URLì„ ë³µì‚¬í•˜ì„¸ìš”!**

---

## Step 6: í…ŒìŠ¤íŠ¸

### ë¡œì»¬ í…ŒìŠ¤íŠ¸
```bash
# ìƒˆ í„°ë¯¸ë„ì—ì„œ
curl http://localhost:8000/health
```

### ì™¸ë¶€ ì ‘ì† í…ŒìŠ¤íŠ¸
```bash
# ngrok URL ì‚¬ìš©
curl https://abc123xyz.ngrok-free.app/health
```

### Pythonìœ¼ë¡œ í…ŒìŠ¤íŠ¸
```python
# test.py
import requests

# ë¡œì»¬ í…ŒìŠ¤íŠ¸
response = requests.post(
    "http://localhost:8000/chat",
    json={"message": "ì•ˆë…•í•˜ì„¸ìš”"}
)
print("ë¡œì»¬:", response.json())

# ngrok í…ŒìŠ¤íŠ¸
response = requests.post(
    "https://abc123xyz.ngrok-free.app/chat",
    json={"message": "ì•ˆë…•í•˜ì„¸ìš”"}
)
print("ì™¸ë¶€:", response.json())
```

---

## Step 7: Cloud Run ì—°ë™

ngrok URLì„ ë°›ì•˜ìœ¼ë©´, Cloud Run ì„œë¹„ìŠ¤ì— ì„¤ì •:

```bash
gcloud run services update nabiyam-chatbot-web \
  --set-env-vars GPU_SERVER_URL=https://abc123xyz.ngrok-free.app \
  --region asia-northeast3 \
  --project rational-autumn-467006-e2
```

---

## ğŸ”§ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### "pythonì´ ì¸ì‹ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤" (Windows)
```powershell
# Python ê²½ë¡œ ì§ì ‘ ì‚¬ìš©
C:\Users\YourName\AppData\Local\Programs\Python\Python310\python.exe gpu_server.py
```

### "í¬íŠ¸ 8000ì´ ì´ë¯¸ ì‚¬ìš© ì¤‘"
```bash
# ë‹¤ë¥¸ í¬íŠ¸ ì‚¬ìš©
python gpu_server.py --port 8001
ngrok http 8001
```

### "CUDA not available" 
â†’ GPU ì—†ê±°ë‚˜ ë“œë¼ì´ë²„ ë¯¸ì„¤ì¹˜. CPUë¡œ ì‘ë™í•©ë‹ˆë‹¤.

### ngrok ì„¸ì…˜ ì¢…ë£Œ (2ì‹œê°„)
â†’ https://ngrok.com ë¬´ë£Œ ê°€ì… í›„ ì¸ì¦ í† í° ì„¤ì •:
```bash
ngrok config add-authtoken YOUR_AUTH_TOKEN
```

---

## âœ… ìµœì¢… ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] Python 3.8+ ì„¤ì¹˜ë¨
- [ ] gpu_server.py íŒŒì¼ ìƒì„±ë¨
- [ ] ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”ë¨
- [ ] íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ (fastapi, uvicorn, torch)
- [ ] ì„œë²„ ì‹¤í–‰ë¨ (http://localhost:8000)
- [ ] ngrok ì„¤ì¹˜ ë° ì‹¤í–‰ë¨
- [ ] ì™¸ë¶€ URL íšë“ (https://xxx.ngrok-free.app)
- [ ] Cloud Runì— URL ì„¤ì •ë¨

---

## ğŸ“Œ ì„œë²„ ìœ ì§€ ê´€ë¦¬

### ì„œë²„ ì‹œì‘ (ë§¤ë²ˆ)
```bash
# í„°ë¯¸ë„ 1
cd ~/skt_teamproject
source naviyam_env/bin/activate  # Linux/Mac
# ë˜ëŠ”
naviyam_env\Scripts\activate  # Windows
python gpu_server.py

# í„°ë¯¸ë„ 2
ngrok http 8000
```

### ìë™ ì‹œì‘ ì„¤ì • (ì„ íƒì‚¬í•­)
Windows: ì‘ì—… ìŠ¤ì¼€ì¤„ëŸ¬ ì‚¬ìš©
Linux: systemd ì„œë¹„ìŠ¤ ìƒì„±
Mac: launchd ì‚¬ìš©